{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b263da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번주에는 배깅, 부스팅, 보팅, 스태킹을 배울 예정이다.\n",
    "# 추천 시스템을 만드는 법을 배울 것이다. 연관규칙이 있다. 상당히 많이 사용된다.\n",
    "# 개인 맞춤형 추천시스템이다. 상당히 많이 쓰이니까 정확히 배우도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d2f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지난 것을 배운것을 복습해보자.------------------------------------------------------------\n",
    "# 배깅을 봤다. 부트스트랩과 어그리게이팅을 합친 용어로 랜덤포레스트가 대표적이다. \n",
    "# 동일한 알고리즘으로 여러 개의 분류기를 생성해서 분류하는 방법이다. \n",
    "# 부트스트랩은 분류 모델을 여러 개 만들어서 서로 다른 학습 데이터로 학습하는 것이다.\n",
    "# 어그리게이팅은 서로 다른 예측값들을 투표를 통해 가장 높은 예측값으로 설정하는 것이다.\n",
    "# 배깅은 병렬이지만 부스팅은 순차적으로 학습이 이루어진다. \n",
    "# 이전 분류기의 학습결과를 바탕으로 다음 분류기의 학습 데이터의 샘플 가중치를 조정하여 학습하는 방법이다.\n",
    "# 동일한 알고리즘 분류기를 순차적으로 학습해서 여러 개의 분류기를 만든 후 테스트할때 가중 투표를 통해 예측값을 결정한다. \n",
    "# XBboost(속도향상이 특징이며 뒤에 두개보다 더 빠르다.또한 오버피팅에 강하다. 병렬수행이 이루어진다. 다만 파라미터가 많아서 보통이 아니다.) \n",
    "# AdaBoost , gradientBoost, \n",
    "# light gbm이 있다. 메모리를 적게 사용하면서 속도가 빠르다. 1만건 이하면 과적합 우려가 크다.  균형잡힌 트리를 유지하면서 분할한다. 오버피팅을 줄이기 위함이다.\n",
    "# 다만 속도에 대한 단점이 존재한다. \n",
    "# 트리라는 단원이 존재한다. 균형잡혀있는 트리가 있고 불균형한 트리가 있다. 균형잡힌 트리는 양쪽의 깊이가 유사한 케이스이다. \n",
    "# XGboost는 트리를 균형있게 만들기 위해 속도가 느려진다. 양쪽은 항상 숫적으로도 균형잡혀야 한다. \n",
    "# light gbm은 로스가 큰 쪽으로 서브트리를 구성한다. 갯수도 반드시 일치할 필요가 없다. \n",
    "# 디시젼트리가 앙상블에서 기본이다. \n",
    "# light gbm도 꽤 순위권이 있는 선호도 높은 트리이다. \n",
    "# 부스팅은 틀린부분에 높은 가중치를 준다. 데이터가 추출될 확률을 높인다. 부스팅은 정렬로 연결해서 결론을 낸다. \n",
    "# 즉 앙상블은 정형 데이터에 대한 분류에 적합하다. 데이터가 정형적인 경우(데이터프레임형식으로 읽을 수 있는 구조가 정해진 데이터)\n",
    "# rnn이나 cnn은 비정형에 사용한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b419b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보팅은 서로 다른 알고리즘으로 학습된 알고리즘 여러개를 모아서 투표하는 방식이다. \n",
    "# 배깅은 같은 알고리즘으로 학습된 알고리즘이다. \n",
    "# 편항과 분산이 중간정도 되는 적정한 시점에 훈련을 멈춰서 적정한 편향과 적정한 분산을 가지도록 해야한다. \n",
    "# 소프트 보팅은 모든 분류기들에 해당되는 확률에 평균을 부여한 것이다. \n",
    "# 하드보팅은 다수결 방식이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4910874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스태킹 구조\n",
    "# 일반적으로 훈련데이터셋으로  모델을 만들고 그것으로 테스트셋을 사용하여 모델의 정확도를 검증한다.  \n",
    "# 스태킹은 구조가 다르다. \n",
    "# 데이터를 svm, 랜덤포레스트, lightgbm 등등 각각의 예측값들을 뽑아내고 이 데이터들이 트레이닝 데이이터로 사용되는 형식이다. \n",
    "# 문제는 과적합이 발생할 수 있다는 것이 단점이다. 일반적으로는 CV를 기반으로 하는 스태킹기법 (K-폴드)이 사용된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2540be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66870d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('titanic/train.csv')\n",
    "test1 = pd.read_csv('titanic/test.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c47189a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본적인 전처리를 진해아였다. \n",
    "data['Embarked'].fillna('S', inplace = True)\n",
    "data['Fare'].fillna(0, inplace=True)\n",
    "data['Fare'] = data['Fare'].map(lambda x : np.log(x) if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed02f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 호칭은 이와 같이 정리했따. \n",
    "data['Initial'] = data['Name'].str.extract('([A-Za-z]+)\\.')\n",
    "data['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr','Other'],inplace=True)\n",
    "mapping = {\n",
    "    \"Mr\":0,\n",
    "    \"Miss\":1,\n",
    "    \"Mrs\" : 1,\n",
    "    \"Master\":2,\n",
    "    \"Other\":3\n",
    "}\n",
    "\n",
    "data['Initial'] = data['Initial'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40311004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대부분의 자료를 숫자형으로 바꾸었다. \n",
    "mapping_sex = {\n",
    "    'male' : 0,\n",
    "    'female': 1\n",
    "}\n",
    "\n",
    "mapping_em = {\n",
    "    'S' :0,\n",
    "    'C' :1,\n",
    "    'Q' :2\n",
    "}\n",
    "\n",
    "\n",
    "data['Sex'] = data['Sex'].map(mapping_sex)\n",
    "data['Embarked'] = data['Embarked'].map(mapping_em)\n",
    "\n",
    "# 필요없는 자료를 날렸다. \n",
    "data.drop(['PassengerId', \"Ticket\", \"Cabin\", \"Name\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ed8f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Initial\n",
       "0    32.739609\n",
       "1    27.834615\n",
       "2     4.574167\n",
       "3    45.888889\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나이에 대한 평균이다. \n",
    "data.groupby('Initial')['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169f0018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터의 숫자들의 평균으로 채워넣었다. \n",
    "data.loc[ (data['Age'].isnull()) & (data['Initial'] == 0), 'Age' ] = 32\n",
    "data.loc[ (data['Age'].isnull()) & (data['Initial'] == 1), 'Age' ] = 28\n",
    "data.loc[ (data['Age'].isnull()) & (data['Initial'] == 2), 'Age' ] = 5\n",
    "data.loc[ (data['Age'].isnull()) & (data['Initial'] == 3), 'Age' ] = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "724245dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Survived']\n",
    "X = data.drop('Survived', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8577d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30262134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤포레스트로 저장하였다. \n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34bf033e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :0.832\n"
     ]
    }
   ],
   "source": [
    "# 모델검증을 하였다. \n",
    "pred = rf.predict(X_test)\n",
    "print(\"정확도 :{0:.3f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fac043dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드 서치를 위한 설정이다. \n",
    "gb_param_grid = {\n",
    "    'n_estimators' : [100, 200],\n",
    "    'max_depth' : [6, 8, 10, 12],\n",
    "    'min_samples_leaf' : [3, 5, 7, 10],\n",
    "    'min_samples_split' : [2, 3, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4ca3c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 먼저 그레디안터 부스팅으로 모델을 만들었다. \n",
    "gb = GradientBoostingClassifier(random_state=0)\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b653845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=GradientBoostingClassifier(random_state=0), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [6, 8, 10, 12],\n",
       "                         &#x27;min_samples_leaf&#x27;: [3, 5, 7, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=GradientBoostingClassifier(random_state=0), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [6, 8, 10, 12],\n",
       "                         &#x27;min_samples_leaf&#x27;: [3, 5, 7, 10],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingClassifier(random_state=0), n_jobs=-1,\n",
       "             param_grid={'max_depth': [6, 8, 10, 12],\n",
       "                         'min_samples_leaf': [3, 5, 7, 10],\n",
       "                         'min_samples_split': [2, 3, 5, 10],\n",
       "                         'n_estimators': [100, 200]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적의 알고리즘을 찾는 과정이다. \n",
    "gb_grid = GridSearchCV(gb, param_grid = gb_param_grid, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "gb_grid.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef0dd7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8272234807446074"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 어째서 랜덤포레스트보다 안좋냐...\n",
    "gb_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fe377c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6,\n",
       " 'min_samples_leaf': 10,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5787c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 좋은 퍼러미터 모델을 먼저 생성하고 타이타닉의 테스트데이터를 입력합니다.\n",
    "# 결과를 제출해봅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f3c56a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1['Embarked'].fillna('S', inplace = True)\n",
    "test1['Fare'].fillna(0, inplace=True)\n",
    "test1['Fare'] = test1['Fare'].map(lambda x : np.log(x) if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68cf17df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1['Initial'] = test1['Name'].str.extract('([A-Za-z]+)\\.')\n",
    "test1['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr','Other'],inplace=True)\n",
    "mapping = {\n",
    "    \"Mr\":0,\n",
    "    \"Miss\":1,\n",
    "    \"Mrs\" : 1,\n",
    "    \"Master\":2,\n",
    "    \"Other\":3\n",
    "}\n",
    "\n",
    "test1['Initial'] = test1['Initial'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e917b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1['Sex'] = test1['Sex'].map(mapping_sex)\n",
    "test1['Embarked'] = test1['Embarked'].map(mapping_em)\n",
    "\n",
    "# 필요없는 자료를 날렸다. \n",
    "test1.drop(['PassengerId', \"Ticket\", \"Cabin\", \"Name\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fa2c150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Initial\n",
       "0    32.114130\n",
       "1    30.203095\n",
       "2     7.406471\n",
       "3    42.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.groupby('Initial')['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db1d03a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.loc[ (test1['Age'].isnull()) & (test1['Initial'] == 0), 'Age' ] = 32\n",
    "test1.loc[ (test1['Age'].isnull()) & (test1['Initial'] == 1), 'Age' ] = 28\n",
    "test1.loc[ (test1['Age'].isnull()) & (test1['Initial'] == 2), 'Age' ] = 5\n",
    "test1.loc[ (test1['Age'].isnull()) & (test1['Initial'] == 3), 'Age' ] = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6124ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfAnswer = rf.predict(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0740440",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbAnswer = gb_grid.predict(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1f75cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer1 = pd.read_csv(\"titanic/gender_submission.csv\")\n",
    "answer2 = answer1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30ae620b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         1\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer1['Survived'] = rfAnswer\n",
    "answer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8876e367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer2['Survived'] = gbAnswer\n",
    "answer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15f3043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer1.to_csv(\"rfsubmission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85b2377a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer2.to_csv(\"gbsubmission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f02b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스태킹\n",
    "# 스태킹은 먼저 기본 모델들을 여러개 사용한다. 거기서 예측값들을 모은다.\n",
    "# 최종모델의 학습데이터가 나오면 lightGBM으로 최종모델을 구축하여 테스트한다.\n",
    "# 최종모델에서의 훈련데이터를 보면 knn 예측값,리니어 리그레션, 랜덤포레스트, xg부스트 등등에서 출력한 결과를 종합하여 훈련데이터를 만든다. \n",
    "# 테스트데이터는 훈련데이터에서 떼서 만든 것으로 진짜 테스트 데이터가 아니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d9de574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 불균형 문제. \n",
    "# 신용카드에 정상적인 신용카드 결제인지 비정상적인 신용카드 결제인지 판단하는 모델을 만들고자 한다.\n",
    "# 신용카드결제는 대부분 정상결제가 많을 것이다. 사실상 1만건 중 1~2건 가량만 존재할 것이다. \n",
    "# 어느 한 쪽만 매우 많은 경우가 데이터가 불균형하다고 한다. 모델을 만들어도 제대로 동작하지 않을 수 있다.\n",
    "# 정확도의 역설\n",
    "# 1만건 중 10건이 비정상거래이다. 그렇다면 전부 다 정상거래라고 분류하면 99.9%의 정확도를 가진다. \n",
    "# 문제는 99.9%라고 해도 여기서는 훌륭하지 않다. \n",
    "# 한쪽으로 불균형한 경우는 모델을 그대로 만들면 안된다. 별도의 추가적인 작업을 진행해야 한다. \n",
    "# 1) 오버샘플링 : 클래스가 적은 쪽의 데이터를 랜덤하게 샘플링하여 복사붙여넣기를 반복하여 두 클래스의 비율을 비슷하게 하는것이다. \n",
    "# 여기서 랜덤 샘플링은 중복이 가능하다.\n",
    "# 2) 언더샘플링 : 클래스가 많은 쪽의 데이터를 랜덤샘플링하여 삭제하여 두 클래스의 비율이 비슷해질때까지 줄이는 것이다.\n",
    "# 일반적으로 언더샘플링은 삭제되는 데이터가 중요한 경우가 있으면 골치가 아파진다. 그래서 오버샘플링하는 경우가 대부분이다.\n",
    "# 3) 오버엔드 언더샘플링 : Yes 클래스가 1000건, No 샘플링은 10건이라고 하자. 두 개를 더해서 2로 나눈다. 505건이 나올 것이다. \n",
    "# Yes는 505건이 될때까지 언더샘플링, No는 505건이 될때까지 오버샘플링을 진행하는 형식이다. \n",
    "# 4) smote 알고리즘 : 이미 패키지가 있다. 데이터를 복사 붙여넣기를 하는게 아니라 유사한 데이터를 만들어내는 것이다. \n",
    "# 기존 데이터를 적절하게 혼합하여 새로운 데이터를 생성하는 방법이다. 오버샘플링이지만 기존 데이터를 쓰는게 아닌 적절하게 혼합하는 형식이다.\n",
    "# 여기서는 KNN알고리즘을 참조한다.  가장 가까운 5개의 데이터를 참조해서 5개 데이터의 중간값을 만든다. 그리고 클래스를 동일하게 해준다. 이렇게 데이터를 만들어 버린 것이다. \n",
    "# 즉 주변 데이터 1개당 1개의 클래스가 만들어진다. 기준데이터와 주변 데이터의 중간값을 계속 만드는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d430a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값이 있고 실제값이 있다. 제 1종오류, 제 2종오류 등이 여기서 나왔다. \n",
    "# 민감도(SE)는 tp/(tp+fn)이다. 즉 암 분류 정답/(암 분류 정답 + 암인데 거짓 분류한것)로 요약 가능하다. \n",
    "# fn이 작을수록 예측도가 높은 것이다. 민감도는 클수록 좋다. \n",
    "# 특이도(SP)는 tn/(tn+fp)이다. 암 음성 정답/(암 음성 정답+ 암 음성 오답)으로 요약한다.\n",
    "# 특이도도 클 수록 좋다. 즉 민감도, 특이도 둘 다 큰 것이 좋다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1ae1116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC커브\n",
    "# 민감도와 특이도가 존재한다. 민감도 & (1-특이도)로 그린 곡선이 ROC곡선이다.\n",
    "# x축이 1-특이도(fp/(tn+fp) = 위양성률:FPR)로 설정되고 y축은 민감도로 설정되는 경우가 대부분이다. \n",
    "# FPR(False Positive Rate) 는 positive로 예측한다. 1이 positive이다 negative가 0이다.  \n",
    "# 0인 케이스를 1로 잘못 예측한 경우(암환자가 아닌데 암환자라고 하는 경우)를 FPR이라고 한다. \n",
    "# 잘못예측한 값이 0에 가까울수록 좋은 모델이다. \n",
    "# TPR(True Positive Rate) 는 positive로 예측해서 맞춘 것이다. \n",
    "# 맞춘값이 1에 가까울수록 좋다. \n",
    "# ROC 커브는 어떤 모델이 좋은 성능을 보이는지 보는 지표로 활용된다. \n",
    "# AUC 커브(area under the curve)는 ROC 커브 밑의 공간이다.\n",
    "# 넓을수록 성능이 높다고 본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3816f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양성과 음성 탐지표.\n",
    "# DEP가 18까지는 DS가 1이고 그 이하는 음성이었다. 기준점 이상이면 1 기준점 이하면 0이라고 예측한다. \n",
    "# ID가 10인 모델이 상당히 좋은 성능을 보이는 것으로 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf81aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신용카드 거래 탐지기\n",
    "# 모델은 보수적으로 구축해야 한다. 즉 피해자를 최소화하는 것으로 목표를 잡아야 한다. \n",
    "# 현 데이터에서는 비정상거래가 0.172%만 존재한다. \n",
    "# PCA(주성분분석)를 통해서 얻어진 결과이다. \n",
    "# 차원축소를 한 이유는 일반적인 정보를 제공하면 안되기 때문이다. \n",
    "# 이 pca과정은 28개의 열이 있다. \n",
    "# time열과 amount열은 남겨두었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd1f0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b16072c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_df = pd.read_csv('creditcard.csv')\n",
    "card_df\n",
    "# 여기서 클래스는 0과 1로 구성되어있고 거의 다 0으로 구성되어있다.\n",
    "# 문제는 train데이터와 test데이터는 나눠지지 않았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6aa318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트레인 테스트 스플릿\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 훈련데이터나 테스트데이터의 비율을 설정하기 위해서 불러온다. \n",
    "# 이번에는 랜덤 스테이트를 써서 난수가 아닌 고정된 값을 추출하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3cb04f95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475829</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382948</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V20       V21  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ...  0.251412 -0.018307   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.524980  0.247998   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.208038 -0.108300   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ...  0.408542 -0.009431   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  1.475829  0.213454   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.059616  0.214205   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.001396  0.232045   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.127434  0.265245   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.382948  0.261057   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0       0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1      -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2       0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3       0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4       0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284802  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n",
       "284803  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n",
       "284804  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n",
       "284805  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n",
       "284806  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n",
       "\n",
       "        Amount  \n",
       "0       149.62  \n",
       "1         2.69  \n",
       "2       378.66  \n",
       "3       123.50  \n",
       "4        69.99  \n",
       "...        ...  \n",
       "284802    0.77  \n",
       "284803   24.79  \n",
       "284804   67.88  \n",
       "284805   10.00  \n",
       "284806  217.00  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features = card_df.iloc[:,:-1] # 정답을 제외한 자료들이다.\n",
    "x_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2670fad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284802    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target = card_df.iloc[:,-1] # 정답만 추출한 자료이다. \n",
    "y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad6f647c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>218489</th>\n",
       "      <td>141335.0</td>\n",
       "      <td>-0.758678</td>\n",
       "      <td>-0.093575</td>\n",
       "      <td>1.663623</td>\n",
       "      <td>-2.318923</td>\n",
       "      <td>-0.039407</td>\n",
       "      <td>0.403720</td>\n",
       "      <td>-0.332983</td>\n",
       "      <td>0.278404</td>\n",
       "      <td>-1.044277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071702</td>\n",
       "      <td>0.400396</td>\n",
       "      <td>0.977369</td>\n",
       "      <td>-0.399793</td>\n",
       "      <td>0.209172</td>\n",
       "      <td>0.656051</td>\n",
       "      <td>0.032054</td>\n",
       "      <td>-0.086935</td>\n",
       "      <td>0.025718</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56731</th>\n",
       "      <td>47560.0</td>\n",
       "      <td>1.272257</td>\n",
       "      <td>0.190183</td>\n",
       "      <td>-0.041974</td>\n",
       "      <td>0.125413</td>\n",
       "      <td>0.517330</td>\n",
       "      <td>0.603855</td>\n",
       "      <td>-0.080820</td>\n",
       "      <td>0.110371</td>\n",
       "      <td>-0.277110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007192</td>\n",
       "      <td>-0.256452</td>\n",
       "      <td>-0.685295</td>\n",
       "      <td>-0.025864</td>\n",
       "      <td>-1.319741</td>\n",
       "      <td>0.330235</td>\n",
       "      <td>0.187871</td>\n",
       "      <td>-0.011459</td>\n",
       "      <td>-0.006342</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227772</th>\n",
       "      <td>145214.0</td>\n",
       "      <td>-1.114859</td>\n",
       "      <td>0.693960</td>\n",
       "      <td>0.520706</td>\n",
       "      <td>0.270798</td>\n",
       "      <td>0.249916</td>\n",
       "      <td>-0.592401</td>\n",
       "      <td>1.125620</td>\n",
       "      <td>-0.472387</td>\n",
       "      <td>-1.662617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.746441</td>\n",
       "      <td>-0.325679</td>\n",
       "      <td>-0.344496</td>\n",
       "      <td>-0.620236</td>\n",
       "      <td>-0.039446</td>\n",
       "      <td>0.905492</td>\n",
       "      <td>-0.224980</td>\n",
       "      <td>-0.390782</td>\n",
       "      <td>0.087134</td>\n",
       "      <td>77.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86066</th>\n",
       "      <td>61069.0</td>\n",
       "      <td>1.271282</td>\n",
       "      <td>0.226519</td>\n",
       "      <td>0.297071</td>\n",
       "      <td>1.112722</td>\n",
       "      <td>0.092594</td>\n",
       "      <td>0.143905</td>\n",
       "      <td>-0.005772</td>\n",
       "      <td>-0.101433</td>\n",
       "      <td>0.420169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021969</td>\n",
       "      <td>-0.129550</td>\n",
       "      <td>-0.025315</td>\n",
       "      <td>-0.250475</td>\n",
       "      <td>-0.584456</td>\n",
       "      <td>0.904605</td>\n",
       "      <td>-0.255660</td>\n",
       "      <td>0.051751</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.436905</td>\n",
       "      <td>0.918966</td>\n",
       "      <td>0.924591</td>\n",
       "      <td>-0.727219</td>\n",
       "      <td>0.915679</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>-0.665271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047021</td>\n",
       "      <td>-0.194796</td>\n",
       "      <td>-0.672638</td>\n",
       "      <td>-0.156858</td>\n",
       "      <td>-0.888386</td>\n",
       "      <td>-0.342413</td>\n",
       "      <td>-0.049027</td>\n",
       "      <td>0.079692</td>\n",
       "      <td>0.131024</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65529</th>\n",
       "      <td>51629.0</td>\n",
       "      <td>1.051352</td>\n",
       "      <td>-0.010657</td>\n",
       "      <td>-0.069235</td>\n",
       "      <td>0.622423</td>\n",
       "      <td>-0.265222</td>\n",
       "      <td>-1.201065</td>\n",
       "      <td>0.612570</td>\n",
       "      <td>-0.379440</td>\n",
       "      <td>-0.268999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170611</td>\n",
       "      <td>-0.305886</td>\n",
       "      <td>-1.168813</td>\n",
       "      <td>0.036048</td>\n",
       "      <td>0.404050</td>\n",
       "      <td>0.256951</td>\n",
       "      <td>0.123656</td>\n",
       "      <td>-0.083804</td>\n",
       "      <td>0.031474</td>\n",
       "      <td>126.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125641</th>\n",
       "      <td>77743.0</td>\n",
       "      <td>-3.171179</td>\n",
       "      <td>-2.640505</td>\n",
       "      <td>1.760183</td>\n",
       "      <td>-0.074576</td>\n",
       "      <td>0.972079</td>\n",
       "      <td>-0.661168</td>\n",
       "      <td>-1.550748</td>\n",
       "      <td>0.861736</td>\n",
       "      <td>-1.307342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452225</td>\n",
       "      <td>0.165517</td>\n",
       "      <td>-0.257406</td>\n",
       "      <td>-0.185918</td>\n",
       "      <td>-0.502941</td>\n",
       "      <td>0.564819</td>\n",
       "      <td>-0.358477</td>\n",
       "      <td>-0.002089</td>\n",
       "      <td>-0.422809</td>\n",
       "      <td>105.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152463</th>\n",
       "      <td>97380.0</td>\n",
       "      <td>1.947526</td>\n",
       "      <td>-0.549009</td>\n",
       "      <td>0.111350</td>\n",
       "      <td>0.378432</td>\n",
       "      <td>-0.866047</td>\n",
       "      <td>0.059364</td>\n",
       "      <td>-1.135662</td>\n",
       "      <td>0.159104</td>\n",
       "      <td>2.562042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.236993</td>\n",
       "      <td>-0.096139</td>\n",
       "      <td>0.039512</td>\n",
       "      <td>0.275335</td>\n",
       "      <td>-0.462707</td>\n",
       "      <td>-0.630365</td>\n",
       "      <td>0.449606</td>\n",
       "      <td>-0.049844</td>\n",
       "      <td>-0.058882</td>\n",
       "      <td>15.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148223</th>\n",
       "      <td>89584.0</td>\n",
       "      <td>1.889354</td>\n",
       "      <td>-0.282130</td>\n",
       "      <td>-0.610005</td>\n",
       "      <td>1.589788</td>\n",
       "      <td>-0.360761</td>\n",
       "      <td>-0.225778</td>\n",
       "      <td>-0.209460</td>\n",
       "      <td>0.099858</td>\n",
       "      <td>1.075368</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380137</td>\n",
       "      <td>-0.292486</td>\n",
       "      <td>-0.566095</td>\n",
       "      <td>0.244231</td>\n",
       "      <td>0.004915</td>\n",
       "      <td>-0.036614</td>\n",
       "      <td>-0.840430</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>-0.054312</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203495</th>\n",
       "      <td>134844.0</td>\n",
       "      <td>0.093525</td>\n",
       "      <td>0.752380</td>\n",
       "      <td>-0.025906</td>\n",
       "      <td>-0.734840</td>\n",
       "      <td>0.613956</td>\n",
       "      <td>-0.756720</td>\n",
       "      <td>0.914471</td>\n",
       "      <td>-0.087598</td>\n",
       "      <td>0.206258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.101280</td>\n",
       "      <td>-0.321146</td>\n",
       "      <td>-0.808846</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>-0.698710</td>\n",
       "      <td>-0.442363</td>\n",
       "      <td>0.185620</td>\n",
       "      <td>0.237188</td>\n",
       "      <td>0.087499</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199364 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "218489  141335.0 -0.758678 -0.093575  1.663623 -2.318923 -0.039407  0.403720   \n",
       "56731    47560.0  1.272257  0.190183 -0.041974  0.125413  0.517330  0.603855   \n",
       "227772  145214.0 -1.114859  0.693960  0.520706  0.270798  0.249916 -0.592401   \n",
       "86066    61069.0  1.271282  0.226519  0.297071  1.112722  0.092594  0.143905   \n",
       "17          13.0 -0.436905  0.918966  0.924591 -0.727219  0.915679 -0.127867   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "65529    51629.0  1.051352 -0.010657 -0.069235  0.622423 -0.265222 -1.201065   \n",
       "125641   77743.0 -3.171179 -2.640505  1.760183 -0.074576  0.972079 -0.661168   \n",
       "152463   97380.0  1.947526 -0.549009  0.111350  0.378432 -0.866047  0.059364   \n",
       "148223   89584.0  1.889354 -0.282130 -0.610005  1.589788 -0.360761 -0.225778   \n",
       "203495  134844.0  0.093525  0.752380 -0.025906 -0.734840  0.613956 -0.756720   \n",
       "\n",
       "              V7        V8        V9  ...       V20       V21       V22  \\\n",
       "218489 -0.332983  0.278404 -1.044277  ...  0.071702  0.400396  0.977369   \n",
       "56731  -0.080820  0.110371 -0.277110  ... -0.007192 -0.256452 -0.685295   \n",
       "227772  1.125620 -0.472387 -1.662617  ... -0.746441 -0.325679 -0.344496   \n",
       "86066  -0.005772 -0.101433  0.420169  ... -0.021969 -0.129550 -0.025315   \n",
       "17      0.707642  0.087962 -0.665271  ... -0.047021 -0.194796 -0.672638   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "65529   0.612570 -0.379440 -0.268999  ...  0.170611 -0.305886 -1.168813   \n",
       "125641 -1.550748  0.861736 -1.307342  ...  0.452225  0.165517 -0.257406   \n",
       "152463 -1.135662  0.159104  2.562042  ... -0.236993 -0.096139  0.039512   \n",
       "148223 -0.209460  0.099858  1.075368  ... -0.380137 -0.292486 -0.566095   \n",
       "203495  0.914471 -0.087598  0.206258  ... -0.101280 -0.321146 -0.808846   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \n",
       "218489 -0.399793  0.209172  0.656051  0.032054 -0.086935  0.025718    0.00  \n",
       "56731  -0.025864 -1.319741  0.330235  0.187871 -0.011459 -0.006342    0.99  \n",
       "227772 -0.620236 -0.039446  0.905492 -0.224980 -0.390782  0.087134   77.96  \n",
       "86066  -0.250475 -0.584456  0.904605 -0.255660  0.051751  0.015862    5.00  \n",
       "17     -0.156858 -0.888386 -0.342413 -0.049027  0.079692  0.131024    0.89  \n",
       "...          ...       ...       ...       ...       ...       ...     ...  \n",
       "65529   0.036048  0.404050  0.256951  0.123656 -0.083804  0.031474  126.90  \n",
       "125641 -0.185918 -0.502941  0.564819 -0.358477 -0.002089 -0.422809  105.47  \n",
       "152463  0.275335 -0.462707 -0.630365  0.449606 -0.049844 -0.058882   15.95  \n",
       "148223  0.244231  0.004915 -0.036614 -0.840430  0.024414 -0.054312   15.00  \n",
       "203495  0.002500 -0.698710 -0.442363  0.185620  0.237188  0.087499    4.49  \n",
       "\n",
       "[199364 rows x 30 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x_features, y_target, test_size = 0.3, random_state=20231023)\n",
    "# 테스트 결과는 무조건 4개로 나눠서 출력한다. \n",
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02537d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131531</th>\n",
       "      <td>79635.0</td>\n",
       "      <td>1.218233</td>\n",
       "      <td>-1.574359</td>\n",
       "      <td>-0.429161</td>\n",
       "      <td>-2.798283</td>\n",
       "      <td>-1.141558</td>\n",
       "      <td>-0.452466</td>\n",
       "      <td>-0.587957</td>\n",
       "      <td>-0.122820</td>\n",
       "      <td>1.373584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212797</td>\n",
       "      <td>-0.366438</td>\n",
       "      <td>-0.670776</td>\n",
       "      <td>-0.343559</td>\n",
       "      <td>-1.024783</td>\n",
       "      <td>0.721007</td>\n",
       "      <td>-0.660220</td>\n",
       "      <td>0.072048</td>\n",
       "      <td>0.040574</td>\n",
       "      <td>159.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20779</th>\n",
       "      <td>31266.0</td>\n",
       "      <td>-0.861456</td>\n",
       "      <td>0.503033</td>\n",
       "      <td>2.201382</td>\n",
       "      <td>-2.371305</td>\n",
       "      <td>-0.275900</td>\n",
       "      <td>-0.340475</td>\n",
       "      <td>0.144616</td>\n",
       "      <td>0.139905</td>\n",
       "      <td>1.180344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127306</td>\n",
       "      <td>0.227341</td>\n",
       "      <td>0.855572</td>\n",
       "      <td>-0.530026</td>\n",
       "      <td>-0.420502</td>\n",
       "      <td>0.738067</td>\n",
       "      <td>-0.608142</td>\n",
       "      <td>0.359031</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>8.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277305</th>\n",
       "      <td>167581.0</td>\n",
       "      <td>1.921107</td>\n",
       "      <td>-0.370702</td>\n",
       "      <td>-1.453793</td>\n",
       "      <td>0.289142</td>\n",
       "      <td>-0.132003</td>\n",
       "      <td>-1.262489</td>\n",
       "      <td>0.310219</td>\n",
       "      <td>-0.417242</td>\n",
       "      <td>0.419387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019924</td>\n",
       "      <td>0.254298</td>\n",
       "      <td>0.652545</td>\n",
       "      <td>-0.049254</td>\n",
       "      <td>-0.030700</td>\n",
       "      <td>0.041877</td>\n",
       "      <td>0.784613</td>\n",
       "      <td>-0.107495</td>\n",
       "      <td>-0.056164</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257906</th>\n",
       "      <td>158403.0</td>\n",
       "      <td>1.480695</td>\n",
       "      <td>-1.147782</td>\n",
       "      <td>0.022041</td>\n",
       "      <td>2.102154</td>\n",
       "      <td>-1.573238</td>\n",
       "      <td>-0.559812</td>\n",
       "      <td>-0.517697</td>\n",
       "      <td>0.075347</td>\n",
       "      <td>1.884497</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077045</td>\n",
       "      <td>0.393911</td>\n",
       "      <td>1.084003</td>\n",
       "      <td>-0.084290</td>\n",
       "      <td>0.928100</td>\n",
       "      <td>0.023426</td>\n",
       "      <td>-0.359473</td>\n",
       "      <td>0.023742</td>\n",
       "      <td>-0.001835</td>\n",
       "      <td>201.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109734</th>\n",
       "      <td>71518.0</td>\n",
       "      <td>-1.217045</td>\n",
       "      <td>0.645251</td>\n",
       "      <td>2.262093</td>\n",
       "      <td>0.194770</td>\n",
       "      <td>-0.351066</td>\n",
       "      <td>-0.302632</td>\n",
       "      <td>0.915108</td>\n",
       "      <td>-0.081826</td>\n",
       "      <td>-0.354096</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112393</td>\n",
       "      <td>0.267942</td>\n",
       "      <td>0.820714</td>\n",
       "      <td>-0.132410</td>\n",
       "      <td>0.411783</td>\n",
       "      <td>0.655951</td>\n",
       "      <td>-0.289953</td>\n",
       "      <td>0.008471</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>108.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251127</th>\n",
       "      <td>155232.0</td>\n",
       "      <td>-3.583557</td>\n",
       "      <td>-3.908531</td>\n",
       "      <td>2.033380</td>\n",
       "      <td>1.519413</td>\n",
       "      <td>4.022362</td>\n",
       "      <td>-3.569249</td>\n",
       "      <td>-2.689987</td>\n",
       "      <td>0.445033</td>\n",
       "      <td>0.448662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.943589</td>\n",
       "      <td>0.688329</td>\n",
       "      <td>0.665744</td>\n",
       "      <td>0.643373</td>\n",
       "      <td>0.404409</td>\n",
       "      <td>-0.004872</td>\n",
       "      <td>-0.612807</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.258959</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95297</th>\n",
       "      <td>65244.0</td>\n",
       "      <td>-1.440108</td>\n",
       "      <td>1.168525</td>\n",
       "      <td>1.812499</td>\n",
       "      <td>0.061799</td>\n",
       "      <td>-0.776294</td>\n",
       "      <td>-0.963881</td>\n",
       "      <td>0.030780</td>\n",
       "      <td>0.427024</td>\n",
       "      <td>-0.184746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124941</td>\n",
       "      <td>0.081654</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>-0.094441</td>\n",
       "      <td>0.699765</td>\n",
       "      <td>0.246975</td>\n",
       "      <td>0.362773</td>\n",
       "      <td>-0.118740</td>\n",
       "      <td>0.056031</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35172</th>\n",
       "      <td>37999.0</td>\n",
       "      <td>0.966128</td>\n",
       "      <td>-0.325948</td>\n",
       "      <td>1.165343</td>\n",
       "      <td>1.558493</td>\n",
       "      <td>-0.848974</td>\n",
       "      <td>0.393648</td>\n",
       "      <td>-0.529057</td>\n",
       "      <td>0.249262</td>\n",
       "      <td>0.983845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063226</td>\n",
       "      <td>-0.113653</td>\n",
       "      <td>-0.198699</td>\n",
       "      <td>-0.008872</td>\n",
       "      <td>0.075133</td>\n",
       "      <td>0.322078</td>\n",
       "      <td>-0.417608</td>\n",
       "      <td>0.072467</td>\n",
       "      <td>0.044287</td>\n",
       "      <td>78.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73670</th>\n",
       "      <td>55229.0</td>\n",
       "      <td>1.321929</td>\n",
       "      <td>-1.351592</td>\n",
       "      <td>0.754017</td>\n",
       "      <td>-1.438044</td>\n",
       "      <td>-1.682644</td>\n",
       "      <td>-0.008625</td>\n",
       "      <td>-1.398072</td>\n",
       "      <td>0.153976</td>\n",
       "      <td>-1.804036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.270792</td>\n",
       "      <td>0.042471</td>\n",
       "      <td>0.410890</td>\n",
       "      <td>-0.020338</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.206929</td>\n",
       "      <td>-0.094400</td>\n",
       "      <td>0.053189</td>\n",
       "      <td>0.020914</td>\n",
       "      <td>59.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35329</th>\n",
       "      <td>38071.0</td>\n",
       "      <td>-0.523331</td>\n",
       "      <td>-3.139373</td>\n",
       "      <td>0.008877</td>\n",
       "      <td>0.270999</td>\n",
       "      <td>-1.607346</td>\n",
       "      <td>0.881539</td>\n",
       "      <td>0.221967</td>\n",
       "      <td>0.223577</td>\n",
       "      <td>1.270468</td>\n",
       "      <td>...</td>\n",
       "      <td>1.501934</td>\n",
       "      <td>0.743148</td>\n",
       "      <td>0.498817</td>\n",
       "      <td>-0.805259</td>\n",
       "      <td>-0.222363</td>\n",
       "      <td>0.085049</td>\n",
       "      <td>-0.465923</td>\n",
       "      <td>-0.046877</td>\n",
       "      <td>0.161194</td>\n",
       "      <td>841.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85443 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "131531   79635.0  1.218233 -1.574359 -0.429161 -2.798283 -1.141558 -0.452466   \n",
       "20779    31266.0 -0.861456  0.503033  2.201382 -2.371305 -0.275900 -0.340475   \n",
       "277305  167581.0  1.921107 -0.370702 -1.453793  0.289142 -0.132003 -1.262489   \n",
       "257906  158403.0  1.480695 -1.147782  0.022041  2.102154 -1.573238 -0.559812   \n",
       "109734   71518.0 -1.217045  0.645251  2.262093  0.194770 -0.351066 -0.302632   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "251127  155232.0 -3.583557 -3.908531  2.033380  1.519413  4.022362 -3.569249   \n",
       "95297    65244.0 -1.440108  1.168525  1.812499  0.061799 -0.776294 -0.963881   \n",
       "35172    37999.0  0.966128 -0.325948  1.165343  1.558493 -0.848974  0.393648   \n",
       "73670    55229.0  1.321929 -1.351592  0.754017 -1.438044 -1.682644 -0.008625   \n",
       "35329    38071.0 -0.523331 -3.139373  0.008877  0.270999 -1.607346  0.881539   \n",
       "\n",
       "              V7        V8        V9  ...       V20       V21       V22  \\\n",
       "131531 -0.587957 -0.122820  1.373584  ... -0.212797 -0.366438 -0.670776   \n",
       "20779   0.144616  0.139905  1.180344  ...  0.127306  0.227341  0.855572   \n",
       "277305  0.310219 -0.417242  0.419387  ... -0.019924  0.254298  0.652545   \n",
       "257906 -0.517697  0.075347  1.884497  ... -0.077045  0.393911  1.084003   \n",
       "109734  0.915108 -0.081826 -0.354096  ... -0.112393  0.267942  0.820714   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "251127 -2.689987  0.445033  0.448662  ...  0.943589  0.688329  0.665744   \n",
       "95297   0.030780  0.427024 -0.184746  ... -0.124941  0.081654  0.084968   \n",
       "35172  -0.529057  0.249262  0.983845  ... -0.063226 -0.113653 -0.198699   \n",
       "73670  -1.398072  0.153976 -1.804036  ... -0.270792  0.042471  0.410890   \n",
       "35329   0.221967  0.223577  1.270468  ...  1.501934  0.743148  0.498817   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \n",
       "131531 -0.343559 -1.024783  0.721007 -0.660220  0.072048  0.040574  159.38  \n",
       "20779  -0.530026 -0.420502  0.738067 -0.608142  0.359031  0.135801    8.49  \n",
       "277305 -0.049254 -0.030700  0.041877  0.784613 -0.107495 -0.056164   95.00  \n",
       "257906 -0.084290  0.928100  0.023426 -0.359473  0.023742 -0.001835  201.60  \n",
       "109734 -0.132410  0.411783  0.655951 -0.289953  0.008471  0.024944  108.00  \n",
       "...          ...       ...       ...       ...       ...       ...     ...  \n",
       "251127  0.643373  0.404409 -0.004872 -0.612807  0.024691  0.258959    1.00  \n",
       "95297  -0.094441  0.699765  0.246975  0.362773 -0.118740  0.056031    2.09  \n",
       "35172  -0.008872  0.075133  0.322078 -0.417608  0.072467  0.044287   78.38  \n",
       "73670  -0.020338  0.001368  0.206929 -0.094400  0.053189  0.020914   59.00  \n",
       "35329  -0.805259 -0.222363  0.085049 -0.465923 -0.046877  0.161194  841.27  \n",
       "\n",
       "[85443 rows x 30 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34ada2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199028\n",
       "1       336\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9a4be86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    85287\n",
       "1      156\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.value_counts()\n",
    "# 문제는 훈련데이터와 테스트데이터의 격차가 크다는 점이다. 비율을 유지하면서 추출하고 싶다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b390a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 층화추출법\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x_features, y_target, test_size = 0.3, random_state=20231023,stratify=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1005c368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43936</th>\n",
       "      <td>41710.0</td>\n",
       "      <td>-0.564819</td>\n",
       "      <td>-0.522687</td>\n",
       "      <td>1.869608</td>\n",
       "      <td>-2.115012</td>\n",
       "      <td>-1.664360</td>\n",
       "      <td>0.470713</td>\n",
       "      <td>-0.166086</td>\n",
       "      <td>0.104985</td>\n",
       "      <td>-2.495465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263493</td>\n",
       "      <td>0.105319</td>\n",
       "      <td>0.647698</td>\n",
       "      <td>-0.080050</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>-0.142767</td>\n",
       "      <td>-0.121838</td>\n",
       "      <td>0.058886</td>\n",
       "      <td>0.069644</td>\n",
       "      <td>146.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27408</th>\n",
       "      <td>34538.0</td>\n",
       "      <td>1.194793</td>\n",
       "      <td>-0.123125</td>\n",
       "      <td>0.129682</td>\n",
       "      <td>0.184620</td>\n",
       "      <td>-0.661332</td>\n",
       "      <td>-1.328738</td>\n",
       "      <td>0.229850</td>\n",
       "      <td>-0.305389</td>\n",
       "      <td>0.336279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030297</td>\n",
       "      <td>-0.043744</td>\n",
       "      <td>-0.094348</td>\n",
       "      <td>-0.081691</td>\n",
       "      <td>0.813879</td>\n",
       "      <td>0.472423</td>\n",
       "      <td>1.097893</td>\n",
       "      <td>-0.106354</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>49.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104623</th>\n",
       "      <td>69155.0</td>\n",
       "      <td>-2.707233</td>\n",
       "      <td>-0.161311</td>\n",
       "      <td>0.205503</td>\n",
       "      <td>-0.460039</td>\n",
       "      <td>-1.884624</td>\n",
       "      <td>0.465420</td>\n",
       "      <td>-0.123742</td>\n",
       "      <td>1.263771</td>\n",
       "      <td>0.310204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.550693</td>\n",
       "      <td>-0.013651</td>\n",
       "      <td>-0.132532</td>\n",
       "      <td>0.125626</td>\n",
       "      <td>-0.173526</td>\n",
       "      <td>-0.627016</td>\n",
       "      <td>0.755108</td>\n",
       "      <td>-0.268901</td>\n",
       "      <td>-0.401017</td>\n",
       "      <td>224.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204177</th>\n",
       "      <td>135147.0</td>\n",
       "      <td>-1.672454</td>\n",
       "      <td>1.136995</td>\n",
       "      <td>0.064399</td>\n",
       "      <td>-1.126974</td>\n",
       "      <td>1.436208</td>\n",
       "      <td>-0.890868</td>\n",
       "      <td>2.468584</td>\n",
       "      <td>-1.612150</td>\n",
       "      <td>1.515508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393086</td>\n",
       "      <td>-0.365509</td>\n",
       "      <td>0.505597</td>\n",
       "      <td>-0.163776</td>\n",
       "      <td>1.150160</td>\n",
       "      <td>-0.249403</td>\n",
       "      <td>0.293392</td>\n",
       "      <td>-1.447625</td>\n",
       "      <td>-1.005972</td>\n",
       "      <td>27.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125545</th>\n",
       "      <td>77712.0</td>\n",
       "      <td>1.049702</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>0.513510</td>\n",
       "      <td>0.488384</td>\n",
       "      <td>0.108871</td>\n",
       "      <td>0.840049</td>\n",
       "      <td>-0.313594</td>\n",
       "      <td>0.411974</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284275</td>\n",
       "      <td>-0.124119</td>\n",
       "      <td>-0.244808</td>\n",
       "      <td>0.312469</td>\n",
       "      <td>-0.660290</td>\n",
       "      <td>-0.164229</td>\n",
       "      <td>0.205209</td>\n",
       "      <td>0.038261</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92254</th>\n",
       "      <td>63847.0</td>\n",
       "      <td>0.886463</td>\n",
       "      <td>-0.836261</td>\n",
       "      <td>0.870844</td>\n",
       "      <td>0.174382</td>\n",
       "      <td>-1.034081</td>\n",
       "      <td>0.210996</td>\n",
       "      <td>-0.474113</td>\n",
       "      <td>0.115984</td>\n",
       "      <td>0.775637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340316</td>\n",
       "      <td>-0.094575</td>\n",
       "      <td>-0.350110</td>\n",
       "      <td>-0.125905</td>\n",
       "      <td>0.129668</td>\n",
       "      <td>0.130776</td>\n",
       "      <td>0.924288</td>\n",
       "      <td>-0.060394</td>\n",
       "      <td>0.030965</td>\n",
       "      <td>166.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282459</th>\n",
       "      <td>170913.0</td>\n",
       "      <td>0.057434</td>\n",
       "      <td>0.741638</td>\n",
       "      <td>-0.017247</td>\n",
       "      <td>-0.727047</td>\n",
       "      <td>0.697449</td>\n",
       "      <td>-0.762813</td>\n",
       "      <td>0.941289</td>\n",
       "      <td>-0.120459</td>\n",
       "      <td>0.114160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041323</td>\n",
       "      <td>-0.308077</td>\n",
       "      <td>-0.760897</td>\n",
       "      <td>0.012980</td>\n",
       "      <td>-0.682384</td>\n",
       "      <td>-0.417804</td>\n",
       "      <td>0.183423</td>\n",
       "      <td>0.238272</td>\n",
       "      <td>0.089988</td>\n",
       "      <td>8.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51466</th>\n",
       "      <td>44957.0</td>\n",
       "      <td>1.167488</td>\n",
       "      <td>-0.789099</td>\n",
       "      <td>0.522642</td>\n",
       "      <td>-0.297890</td>\n",
       "      <td>-1.376580</td>\n",
       "      <td>-1.040312</td>\n",
       "      <td>-0.312282</td>\n",
       "      <td>-0.255328</td>\n",
       "      <td>-0.701929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284241</td>\n",
       "      <td>-0.541580</td>\n",
       "      <td>-1.200824</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>0.732098</td>\n",
       "      <td>0.051128</td>\n",
       "      <td>0.824153</td>\n",
       "      <td>-0.065557</td>\n",
       "      <td>0.030471</td>\n",
       "      <td>104.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172159</th>\n",
       "      <td>120984.0</td>\n",
       "      <td>-0.918638</td>\n",
       "      <td>1.236696</td>\n",
       "      <td>-0.547918</td>\n",
       "      <td>0.564548</td>\n",
       "      <td>0.455278</td>\n",
       "      <td>-1.000943</td>\n",
       "      <td>1.631397</td>\n",
       "      <td>-0.020448</td>\n",
       "      <td>-1.058048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315515</td>\n",
       "      <td>0.238789</td>\n",
       "      <td>0.493895</td>\n",
       "      <td>-0.332234</td>\n",
       "      <td>-0.104482</td>\n",
       "      <td>0.365574</td>\n",
       "      <td>-0.422198</td>\n",
       "      <td>-0.083873</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>117.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57064</th>\n",
       "      <td>47735.0</td>\n",
       "      <td>0.166446</td>\n",
       "      <td>0.350155</td>\n",
       "      <td>1.316529</td>\n",
       "      <td>0.439153</td>\n",
       "      <td>-0.627878</td>\n",
       "      <td>-0.175258</td>\n",
       "      <td>-0.269247</td>\n",
       "      <td>-0.688954</td>\n",
       "      <td>0.213776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.289765</td>\n",
       "      <td>0.747796</td>\n",
       "      <td>-0.187491</td>\n",
       "      <td>-0.178349</td>\n",
       "      <td>0.565139</td>\n",
       "      <td>0.761120</td>\n",
       "      <td>0.437004</td>\n",
       "      <td>0.130355</td>\n",
       "      <td>0.205052</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199364 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "43936    41710.0 -0.564819 -0.522687  1.869608 -2.115012 -1.664360  0.470713   \n",
       "27408    34538.0  1.194793 -0.123125  0.129682  0.184620 -0.661332 -1.328738   \n",
       "104623   69155.0 -2.707233 -0.161311  0.205503 -0.460039 -1.884624  0.465420   \n",
       "204177  135147.0 -1.672454  1.136995  0.064399 -1.126974  1.436208 -0.890868   \n",
       "125545   77712.0  1.049702 -0.000133  0.513510  0.488384  0.108871  0.840049   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "92254    63847.0  0.886463 -0.836261  0.870844  0.174382 -1.034081  0.210996   \n",
       "282459  170913.0  0.057434  0.741638 -0.017247 -0.727047  0.697449 -0.762813   \n",
       "51466    44957.0  1.167488 -0.789099  0.522642 -0.297890 -1.376580 -1.040312   \n",
       "172159  120984.0 -0.918638  1.236696 -0.547918  0.564548  0.455278 -1.000943   \n",
       "57064    47735.0  0.166446  0.350155  1.316529  0.439153 -0.627878 -0.175258   \n",
       "\n",
       "              V7        V8        V9  ...       V20       V21       V22  \\\n",
       "43936  -0.166086  0.104985 -2.495465  ... -0.263493  0.105319  0.647698   \n",
       "27408   0.229850 -0.305389  0.336279  ... -0.030297 -0.043744 -0.094348   \n",
       "104623 -0.123742  1.263771  0.310204  ... -0.550693 -0.013651 -0.132532   \n",
       "204177  2.468584 -1.612150  1.515508  ...  0.393086 -0.365509  0.505597   \n",
       "125545 -0.313594  0.411974  0.109100  ... -0.284275 -0.124119 -0.244808   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "92254  -0.474113  0.115984  0.775637  ...  0.340316 -0.094575 -0.350110   \n",
       "282459  0.941289 -0.120459  0.114160  ... -0.041323 -0.308077 -0.760897   \n",
       "51466  -0.312282 -0.255328 -0.701929  ... -0.284241 -0.541580 -1.200824   \n",
       "172159  1.631397 -0.020448 -1.058048  ... -0.315515  0.238789  0.493895   \n",
       "57064  -0.269247 -0.688954  0.213776  ... -0.289765  0.747796 -0.187491   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \n",
       "43936  -0.080050  0.005834 -0.142767 -0.121838  0.058886  0.069644  146.00  \n",
       "27408  -0.081691  0.813879  0.472423  1.097893 -0.106354  0.002651   49.50  \n",
       "104623  0.125626 -0.173526 -0.627016  0.755108 -0.268901 -0.401017  224.54  \n",
       "204177 -0.163776  1.150160 -0.249403  0.293392 -1.447625 -1.005972   27.48  \n",
       "125545  0.312469 -0.660290 -0.164229  0.205209  0.038261  0.006133    1.98  \n",
       "...          ...       ...       ...       ...       ...       ...     ...  \n",
       "92254  -0.125905  0.129668  0.130776  0.924288 -0.060394  0.030965  166.93  \n",
       "282459  0.012980 -0.682384 -0.417804  0.183423  0.238272  0.089988    8.61  \n",
       "51466   0.115950  0.732098  0.051128  0.824153 -0.065557  0.030471  104.70  \n",
       "172159 -0.332234 -0.104482  0.365574 -0.422198 -0.083873  0.001332  117.00  \n",
       "57064  -0.178349  0.565139  0.761120  0.437004  0.130355  0.205052   10.00  \n",
       "\n",
       "[199364 rows x 30 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f53f13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203724</th>\n",
       "      <td>134937.0</td>\n",
       "      <td>2.017407</td>\n",
       "      <td>-1.320911</td>\n",
       "      <td>-0.924768</td>\n",
       "      <td>-0.891668</td>\n",
       "      <td>-1.071416</td>\n",
       "      <td>-0.460661</td>\n",
       "      <td>-0.942455</td>\n",
       "      <td>0.075088</td>\n",
       "      <td>0.067273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038263</td>\n",
       "      <td>0.252061</td>\n",
       "      <td>0.502590</td>\n",
       "      <td>0.097229</td>\n",
       "      <td>-0.432676</td>\n",
       "      <td>-0.246943</td>\n",
       "      <td>-0.172660</td>\n",
       "      <td>-0.033324</td>\n",
       "      <td>-0.058974</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>10232.0</td>\n",
       "      <td>1.027649</td>\n",
       "      <td>-1.312481</td>\n",
       "      <td>0.966172</td>\n",
       "      <td>-0.342725</td>\n",
       "      <td>-1.596198</td>\n",
       "      <td>0.092919</td>\n",
       "      <td>-1.223895</td>\n",
       "      <td>0.126081</td>\n",
       "      <td>1.124267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300857</td>\n",
       "      <td>0.270221</td>\n",
       "      <td>0.639126</td>\n",
       "      <td>-0.272279</td>\n",
       "      <td>-0.024808</td>\n",
       "      <td>0.346075</td>\n",
       "      <td>-0.095181</td>\n",
       "      <td>-0.019920</td>\n",
       "      <td>0.031142</td>\n",
       "      <td>171.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25622</th>\n",
       "      <td>33691.0</td>\n",
       "      <td>-0.237188</td>\n",
       "      <td>0.220923</td>\n",
       "      <td>0.383906</td>\n",
       "      <td>-0.200345</td>\n",
       "      <td>0.410422</td>\n",
       "      <td>-0.541870</td>\n",
       "      <td>1.607151</td>\n",
       "      <td>-0.535403</td>\n",
       "      <td>-0.631439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548045</td>\n",
       "      <td>0.037438</td>\n",
       "      <td>-0.000579</td>\n",
       "      <td>0.069943</td>\n",
       "      <td>-0.385964</td>\n",
       "      <td>0.099211</td>\n",
       "      <td>1.132368</td>\n",
       "      <td>-0.278196</td>\n",
       "      <td>-0.201108</td>\n",
       "      <td>164.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76700</th>\n",
       "      <td>56703.0</td>\n",
       "      <td>1.197048</td>\n",
       "      <td>-0.516517</td>\n",
       "      <td>0.445305</td>\n",
       "      <td>-0.260484</td>\n",
       "      <td>-0.645504</td>\n",
       "      <td>0.126351</td>\n",
       "      <td>-0.509842</td>\n",
       "      <td>0.080492</td>\n",
       "      <td>-1.262008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371208</td>\n",
       "      <td>-0.572873</td>\n",
       "      <td>-1.296547</td>\n",
       "      <td>0.188383</td>\n",
       "      <td>-0.340981</td>\n",
       "      <td>-0.040320</td>\n",
       "      <td>0.058675</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>0.020308</td>\n",
       "      <td>56.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143660</th>\n",
       "      <td>85519.0</td>\n",
       "      <td>-0.609381</td>\n",
       "      <td>0.838004</td>\n",
       "      <td>0.421976</td>\n",
       "      <td>0.299191</td>\n",
       "      <td>-0.621679</td>\n",
       "      <td>-1.059325</td>\n",
       "      <td>1.232548</td>\n",
       "      <td>0.016567</td>\n",
       "      <td>-1.035704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252908</td>\n",
       "      <td>0.222442</td>\n",
       "      <td>0.310052</td>\n",
       "      <td>0.376891</td>\n",
       "      <td>0.761915</td>\n",
       "      <td>-0.126045</td>\n",
       "      <td>0.230400</td>\n",
       "      <td>-0.169019</td>\n",
       "      <td>-0.016019</td>\n",
       "      <td>170.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71071</th>\n",
       "      <td>54137.0</td>\n",
       "      <td>1.112634</td>\n",
       "      <td>0.522789</td>\n",
       "      <td>1.068855</td>\n",
       "      <td>2.514559</td>\n",
       "      <td>-0.313505</td>\n",
       "      <td>-0.117546</td>\n",
       "      <td>-0.117439</td>\n",
       "      <td>0.056953</td>\n",
       "      <td>-0.654020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175697</td>\n",
       "      <td>-0.045880</td>\n",
       "      <td>-0.127814</td>\n",
       "      <td>0.142695</td>\n",
       "      <td>0.383513</td>\n",
       "      <td>0.193416</td>\n",
       "      <td>-0.121273</td>\n",
       "      <td>0.023632</td>\n",
       "      <td>0.030464</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22191</th>\n",
       "      <td>32094.0</td>\n",
       "      <td>1.267090</td>\n",
       "      <td>-0.852580</td>\n",
       "      <td>0.917346</td>\n",
       "      <td>-0.646427</td>\n",
       "      <td>-1.409034</td>\n",
       "      <td>-0.261406</td>\n",
       "      <td>-1.098706</td>\n",
       "      <td>0.099025</td>\n",
       "      <td>-0.317206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088953</td>\n",
       "      <td>0.422390</td>\n",
       "      <td>1.106223</td>\n",
       "      <td>-0.094646</td>\n",
       "      <td>0.115737</td>\n",
       "      <td>0.322579</td>\n",
       "      <td>-0.021588</td>\n",
       "      <td>0.043943</td>\n",
       "      <td>0.027040</td>\n",
       "      <td>45.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155166</th>\n",
       "      <td>104669.0</td>\n",
       "      <td>-0.735421</td>\n",
       "      <td>0.961008</td>\n",
       "      <td>2.182693</td>\n",
       "      <td>-0.369619</td>\n",
       "      <td>0.319295</td>\n",
       "      <td>0.233361</td>\n",
       "      <td>0.414002</td>\n",
       "      <td>-0.080052</td>\n",
       "      <td>1.450639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198223</td>\n",
       "      <td>-0.306548</td>\n",
       "      <td>-0.370366</td>\n",
       "      <td>-0.350986</td>\n",
       "      <td>-0.499051</td>\n",
       "      <td>0.316956</td>\n",
       "      <td>-0.717508</td>\n",
       "      <td>0.027570</td>\n",
       "      <td>-0.095555</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198614</th>\n",
       "      <td>132569.0</td>\n",
       "      <td>-0.939623</td>\n",
       "      <td>0.376995</td>\n",
       "      <td>0.860728</td>\n",
       "      <td>-2.857571</td>\n",
       "      <td>0.641112</td>\n",
       "      <td>0.264287</td>\n",
       "      <td>0.622707</td>\n",
       "      <td>-0.109557</td>\n",
       "      <td>-0.871124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361226</td>\n",
       "      <td>0.028229</td>\n",
       "      <td>0.306291</td>\n",
       "      <td>-0.650067</td>\n",
       "      <td>-1.435399</td>\n",
       "      <td>1.037138</td>\n",
       "      <td>-0.067965</td>\n",
       "      <td>0.044885</td>\n",
       "      <td>-0.077683</td>\n",
       "      <td>20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96583</th>\n",
       "      <td>65834.0</td>\n",
       "      <td>-0.607239</td>\n",
       "      <td>0.539003</td>\n",
       "      <td>-0.082346</td>\n",
       "      <td>-0.677416</td>\n",
       "      <td>2.916778</td>\n",
       "      <td>3.193351</td>\n",
       "      <td>0.303041</td>\n",
       "      <td>0.795760</td>\n",
       "      <td>-1.161121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364531</td>\n",
       "      <td>-0.341874</td>\n",
       "      <td>-1.312175</td>\n",
       "      <td>-0.055310</td>\n",
       "      <td>0.995930</td>\n",
       "      <td>0.251481</td>\n",
       "      <td>0.333888</td>\n",
       "      <td>-0.012409</td>\n",
       "      <td>0.066958</td>\n",
       "      <td>26.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85443 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "203724  134937.0  2.017407 -1.320911 -0.924768 -0.891668 -1.071416 -0.460661   \n",
       "7499     10232.0  1.027649 -1.312481  0.966172 -0.342725 -1.596198  0.092919   \n",
       "25622    33691.0 -0.237188  0.220923  0.383906 -0.200345  0.410422 -0.541870   \n",
       "76700    56703.0  1.197048 -0.516517  0.445305 -0.260484 -0.645504  0.126351   \n",
       "143660   85519.0 -0.609381  0.838004  0.421976  0.299191 -0.621679 -1.059325   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "71071    54137.0  1.112634  0.522789  1.068855  2.514559 -0.313505 -0.117546   \n",
       "22191    32094.0  1.267090 -0.852580  0.917346 -0.646427 -1.409034 -0.261406   \n",
       "155166  104669.0 -0.735421  0.961008  2.182693 -0.369619  0.319295  0.233361   \n",
       "198614  132569.0 -0.939623  0.376995  0.860728 -2.857571  0.641112  0.264287   \n",
       "96583    65834.0 -0.607239  0.539003 -0.082346 -0.677416  2.916778  3.193351   \n",
       "\n",
       "              V7        V8        V9  ...       V20       V21       V22  \\\n",
       "203724 -0.942455  0.075088  0.067273  ... -0.038263  0.252061  0.502590   \n",
       "7499   -1.223895  0.126081  1.124267  ...  0.300857  0.270221  0.639126   \n",
       "25622   1.607151 -0.535403 -0.631439  ...  0.548045  0.037438 -0.000579   \n",
       "76700  -0.509842  0.080492 -1.262008  ... -0.371208 -0.572873 -1.296547   \n",
       "143660  1.232548  0.016567 -1.035704  ...  0.252908  0.222442  0.310052   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "71071  -0.117439  0.056953 -0.654020  ... -0.175697 -0.045880 -0.127814   \n",
       "22191  -1.098706  0.099025 -0.317206  ...  0.088953  0.422390  1.106223   \n",
       "155166  0.414002 -0.080052  1.450639  ...  0.198223 -0.306548 -0.370366   \n",
       "198614  0.622707 -0.109557 -0.871124  ...  0.361226  0.028229  0.306291   \n",
       "96583   0.303041  0.795760 -1.161121  ...  0.364531 -0.341874 -1.312175   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \n",
       "203724  0.097229 -0.432676 -0.246943 -0.172660 -0.033324 -0.058974   80.00  \n",
       "7499   -0.272279 -0.024808  0.346075 -0.095181 -0.019920  0.031142  171.77  \n",
       "25622   0.069943 -0.385964  0.099211  1.132368 -0.278196 -0.201108  164.85  \n",
       "76700   0.188383 -0.340981 -0.040320  0.058675  0.006745  0.020308   56.19  \n",
       "143660  0.376891  0.761915 -0.126045  0.230400 -0.169019 -0.016019  170.13  \n",
       "...          ...       ...       ...       ...       ...       ...     ...  \n",
       "71071   0.142695  0.383513  0.193416 -0.121273  0.023632  0.030464    0.77  \n",
       "22191  -0.094646  0.115737  0.322579 -0.021588  0.043943  0.027040   45.00  \n",
       "155166 -0.350986 -0.499051  0.316956 -0.717508  0.027570 -0.095555    2.30  \n",
       "198614 -0.650067 -1.435399  1.037138 -0.067965  0.044885 -0.077683   20.00  \n",
       "96583  -0.055310  0.995930  0.251481  0.333888 -0.012409  0.066958   26.95  \n",
       "\n",
       "[85443 rows x 30 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef26d07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199020\n",
       "1       344\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e1fa7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    85295\n",
       "1      148\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3c39e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.drop('Time', axis=1, inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "199cae57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V21       V22  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ... -0.018307  0.277838   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.247998  0.771679   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.214205  0.924384   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.232045  0.578229   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.265245  0.800049   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy = get_preprocessed_df(card_df)\n",
    "df_copy# 이렇게 변수가 완성되었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cebe9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5164e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_dataset(df=None):\n",
    "    df_copy = get_preprocessed_df(df)\n",
    "    X_features = df_copy.iloc[:, :-1]\n",
    "    y_target = df_copy.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_features, y_target, test_size=0.3, random_state=0, stratify=y_target)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ccdfa09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    99.827451\n",
      "1     0.172549\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts()/y_train.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53a2c74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    99.826785\n",
      "1     0.173215\n",
      "Name: Class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_test.value_counts()/y_test.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "428639c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 로지스틱 회귀모델을 통해서 예측을 수행해보자. \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b316846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀모델을 제작하여 객체를 생성하는 작업이다.\n",
    "lr_clf = LogisticRegression() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5b6d42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "680fc7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4a75284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#방금은 예측결과를 도출하는 코드를 만들었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8991083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression\n",
    "# 즉 선형회귀이다. \n",
    "# x변수에는 공부시간. y축은 점수 이런 식의 데이터프레임형식으로 나타내어진다.\n",
    "# 모델을 만들때는 데이터의 분포를 봐야한다. \n",
    "# 데이터의 분포가 선형적인 특징이 있다는 가설함수를 먼저 세운다. \n",
    "# H(x) = Wx + b처럼 직선을 가진다고 가정한다. \n",
    "# 우리는 그 직선을 찾는 것이 목적이다. 직선과 점사이의 거리가 가장 짧은 직선이 좋은 직선이라고 본다.\n",
    "# cost function은 비용함수로 작을수록 좋다고 판단한다. \n",
    "# H(x)-y로 나타내는데 H(x)는 예측값, y는 실제값이다. 예측값과 실제값의 차이를 애러(error)라고 한다. \n",
    "# 궁극적으로 찾고자 하는 함수그래프이다. \n",
    "# 그 애러들의 평균을 cost라고 한다. 즉 비용이다 \n",
    "# 즉 애러의 평균이 비용함수이다. \n",
    "# goal은 비용을 최소로 하는 지점이다. 이걸 하기 위해.경사하강법(gradient descent algoreihm)이라고 한다.\n",
    "# goal에 가까운 지점을 찾는 것. 이걸 기계가 스스로 찾아나가는 것이다. \n",
    "# 다차원 데이터인 경우에도 가능하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57d88b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사하강법의 구동원리\n",
    "# 일단 시작은 아무곳에서나 시작한다. \n",
    "# 약간씩 변환을 시키면서 코스트를 낮춘다. \n",
    "# 계속 반복한다.\n",
    "# 그리고 가장 작은 부분을 찾아낸다. \n",
    "# 이걸 계속 반복하는 것이다. \n",
    "# 미분은 기울기 구하라는 이야기이다. 미분은 순간기울기이다. 미분계수가 양수인지 음수인지를 보는 것이다. \n",
    "# 러닝메이트값(a, 하이퍼파라미터라고도 함)을 어떻게 설정하느냐도 매우 중요하다. (딥러닝 기초 89페이지)\n",
    "# 텐서플로우건 파이토치건 경사하강법이 구현되어있다. 텐서플로우 하는 시절에는 일일히 구현했다. \n",
    "# 결국 convex function을 찾는 여정이다. 최저점을 찾아내는 과정이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42f40e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 분류(또는 회귀)\n",
    "# 연속형 값을 예측할 수 있는 모델을 만들 수 있게된다.\n",
    "# x데이터가 어느 것이 되더라도 y값을 예측할 수 있게 된다. \n",
    "# 0 또는 1로 분류하는 작업이다. 스팸메일 분류, 페이스북 피드, 신용카드 불법사용 분류 등 이진분류에서 활용한다. \n",
    "# 시그모이드함수(딥러닝기초 130페이지)가 중요하다. s자 모양으로 생겼으며 -1~1까지의 범위를 가진다. \n",
    "# 1 / 1+e**-(W**t*X)로 표현한다. 이게 시그모이드 함수이다. \n",
    "# 0.5보다 크면 1로. 0,5보다 작으면 0으로 만드는 것이다. \n",
    "# 문제는 H(x) = Wx+b는 U자로 생겨서 찾기가 생각보다 쉽다. 문제는 시그모이드함수는 잘못 대입하면 '로컬 미니멈 문제'가 발생한다.\n",
    "# 우리는 글로벌 미니멈을 찾아야 하는데 로컬 미니멈만 찾고 끝내버린다. 즉 산골자기가 엄청 만들어지는데 그 산골자기가 한개만 찍고 끝내는 것이다.\n",
    "# 그것을 해결한 공식이 -log(H(x))와 -log(1-H(x))이다. 정답이 1이면 전자. 정답이 0이면 후자로 대입하면 된다. \n",
    "# 텐서플로우 난이도를 높인 주범 중 하나이다. 이것은 매우 어려운 공식이어서 쉽지 않다. \n",
    "# 시그모이드 함수는 이진분류기를 제작하는데 사용된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dfe7417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소프트맥스 크로스 엔트로피 \n",
    "# 분류해야하는 수가 많을 경우 분류기는 여러 가지가 존재할 수 있다. (딥러닝기초 143페이지)\n",
    "# 클래스의 갯수만큼 분류기를 만들면 된다. \n",
    "# 각각의 분류기를 돌려서 함수에 투입했을때 튀어나오는 값이 다르다. (딥러닝기초 144페이지)\n",
    "# 다중분류는 소프트맥스 함수를 반드시 사용한다. \n",
    "# 연산한 값(score)을 전달받아서 확률(probabilities)이 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "879ae3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정리\n",
    "# 선형회귀 : x는 독립변수, y는 종속변수이다. 코스트는 H(x) = Wx + b 에서 H(x)-y를 계산하여 원점에서 떨어진 거리를 나타낸다.\n",
    "# 그리고 이걸 편미분해서 U자 형태로 계산할 수 있다. \n",
    "# 시그모이드 : -1 ~ 1까지의 범위를 가진다. 이거 쓰려고 했는데 산골짜기가 여러개 생겨서 도저히 써먹을 수 없었다. (로컬 미니멈) \n",
    "# 로지스틱 이진분류 :그래서 로그 써서 어떻게든 풀어보려고 했던 역사이다.\n",
    "# 소프트맥스 : 그리고 여러개를 둬서 다중분류를 할 수 있게 되었다. 분류기를 클래스의 종류만큼 만들어버리면 분류가 가능해진다.\n",
    "# 그래서 이걸 원핫인코딩으로 다중분류 해버리는 것이다!\n",
    "# 딥러닝 : 입력과 출력사이에 레이어를 둔 것을 말한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48c10aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    85341\n",
       "1      102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lr_clf.predict(X_test)).value_counts()\n",
    "# 정답판단은 이렇게 하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "20d4f22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.98651690e-01, 1.34831002e-03],\n",
       "       [9.99876546e-01, 1.23454097e-04],\n",
       "       [9.99808217e-01, 1.91783045e-04],\n",
       "       ...,\n",
       "       [9.99753313e-01, 2.46686772e-04],\n",
       "       [9.99253336e-01, 7.46664288e-04],\n",
       "       [9.99865249e-01, 1.34751489e-04]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.predict_proba(X_test) # 프로바는 확률로 나눈 것을 출력해주는 함수이다.  \n",
    "# 즉 0이 나올 확률과 1이 나올 확률이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "03ce5c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00134831, 0.00012345, 0.00019178, ..., 0.00024669, 0.00074666,\n",
       "       0.00013475])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.predict_proba(X_test)[:,1] \n",
    "#1번 인덱스에 해당하는 것들이 전부 나왔다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d47c9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#내일은 light gbm을 돌려볼 것이다. AUC도 출력해볼 것이다. 어제 했던 절차를 이어서 전행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb37755d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Obtaining dependency information for lightgbm from https://files.pythonhosted.org/packages/b3/f8/ee33e36194eb03a76eccf3adac3fba51f0e56fbd20609bb531659d48d3cb/lightgbm-4.1.0-py3-none-win_amd64.whl.metadata\n",
      "  Downloading lightgbm-4.1.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from lightgbm) (1.10.1)\n",
      "Downloading lightgbm-4.1.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.6/1.3 MB 19.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 21.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 12.0 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# light gbm을 돌려보자. 먼저 설치부터 진행한다. \n",
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91ef33d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# light gbm은 속도가 빠르다. XG부스트보다 빠르게 수행되어진다. \n",
    "# 작년까지만 해도 케글이나 공모전에서 많이 사용되었던 모델이다. \n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5118498d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(boost_from_average=False, n_estimators=1000, num_leaves=64)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(boost_from_average=False, n_estimators=1000, num_leaves=64)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(boost_from_average=False, n_estimators=1000, num_leaves=64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=1000,num_leaves=64, boost_from_average=False)\n",
    "lgbm_clf\n",
    "# boost_from_average는 데이터 불균형 분포시 False로 설정하는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "96648dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 344, number of negative: 199020\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7395\n",
      "[LightGBM] [Info] Number of data points in the train set: 199364, number of used features: 29\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(boost_from_average=False, n_estimators=1000, num_leaves=64)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(boost_from_average=False, n_estimators=1000, num_leaves=64)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(boost_from_average=False, n_estimators=1000, num_leaves=64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf.fit(X_train,y_train)\n",
    "# 모델을 제작해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4fcba40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = lgbm_clf.predict(X_test)\n",
    "pred\n",
    "# 이것이 결과값이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6d8a0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99999997e-01, 3.49830240e-09],\n",
       "       [1.00000000e+00, 1.08517297e-10],\n",
       "       [1.00000000e+00, 2.23232317e-10],\n",
       "       ...,\n",
       "       [9.99999996e-01, 3.66393546e-09],\n",
       "       [9.99999999e-01, 6.63996306e-10],\n",
       "       [1.00000000e+00, 1.08138237e-10]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf.predict_proba(X_test)\n",
    "# 확률로 출력해보았다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d2e4adea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "      <td>199364.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000386</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000806</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>-0.000907</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>88.286313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.959976</td>\n",
       "      <td>1.658734</td>\n",
       "      <td>1.512912</td>\n",
       "      <td>1.413217</td>\n",
       "      <td>1.362707</td>\n",
       "      <td>1.322962</td>\n",
       "      <td>1.216585</td>\n",
       "      <td>1.191216</td>\n",
       "      <td>1.098032</td>\n",
       "      <td>1.086637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774205</td>\n",
       "      <td>0.736703</td>\n",
       "      <td>0.724805</td>\n",
       "      <td>0.630090</td>\n",
       "      <td>0.605543</td>\n",
       "      <td>0.520830</td>\n",
       "      <td>0.482453</td>\n",
       "      <td>0.401370</td>\n",
       "      <td>0.330830</td>\n",
       "      <td>248.033917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-32.965346</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-35.182120</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.009635</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-11.710896</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.921490</td>\n",
       "      <td>-0.598848</td>\n",
       "      <td>-0.889918</td>\n",
       "      <td>-0.849806</td>\n",
       "      <td>-0.690631</td>\n",
       "      <td>-0.767513</td>\n",
       "      <td>-0.556268</td>\n",
       "      <td>-0.207917</td>\n",
       "      <td>-0.642713</td>\n",
       "      <td>-0.535148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211459</td>\n",
       "      <td>-0.227817</td>\n",
       "      <td>-0.540206</td>\n",
       "      <td>-0.162056</td>\n",
       "      <td>-0.353481</td>\n",
       "      <td>-0.317180</td>\n",
       "      <td>-0.328089</td>\n",
       "      <td>-0.070961</td>\n",
       "      <td>-0.053200</td>\n",
       "      <td>5.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.015893</td>\n",
       "      <td>0.065727</td>\n",
       "      <td>0.180635</td>\n",
       "      <td>-0.019842</td>\n",
       "      <td>-0.054758</td>\n",
       "      <td>-0.273142</td>\n",
       "      <td>0.040109</td>\n",
       "      <td>0.023008</td>\n",
       "      <td>-0.050546</td>\n",
       "      <td>-0.091521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062514</td>\n",
       "      <td>-0.028990</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>-0.011301</td>\n",
       "      <td>0.041293</td>\n",
       "      <td>0.016244</td>\n",
       "      <td>-0.053516</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.011043</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.316633</td>\n",
       "      <td>0.804333</td>\n",
       "      <td>1.028314</td>\n",
       "      <td>0.744065</td>\n",
       "      <td>0.609794</td>\n",
       "      <td>0.400874</td>\n",
       "      <td>0.570132</td>\n",
       "      <td>0.327720</td>\n",
       "      <td>0.597585</td>\n",
       "      <td>0.456096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133886</td>\n",
       "      <td>0.186863</td>\n",
       "      <td>0.529286</td>\n",
       "      <td>0.147035</td>\n",
       "      <td>0.440205</td>\n",
       "      <td>0.351141</td>\n",
       "      <td>0.240123</td>\n",
       "      <td>0.090888</td>\n",
       "      <td>0.078216</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.454930</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>21.550496</td>\n",
       "      <td>36.877368</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>23.745136</td>\n",
       "      <td>...</td>\n",
       "      <td>39.420904</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.022866</td>\n",
       "      <td>6.070850</td>\n",
       "      <td>3.463246</td>\n",
       "      <td>12.152401</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>19656.530000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  V1             V2             V3             V4  \\\n",
       "count  199364.000000  199364.000000  199364.000000  199364.000000   \n",
       "mean        0.000386      -0.000637       0.000587      -0.001239   \n",
       "std         1.959976       1.658734       1.512912       1.413217   \n",
       "min       -56.407510     -72.715728     -32.965346      -5.683171   \n",
       "25%        -0.921490      -0.598848      -0.889918      -0.849806   \n",
       "50%         0.015893       0.065727       0.180635      -0.019842   \n",
       "75%         1.316633       0.804333       1.028314       0.744065   \n",
       "max         2.454930      22.057729       9.382558      16.875344   \n",
       "\n",
       "                  V5             V6             V7             V8  \\\n",
       "count  199364.000000  199364.000000  199364.000000  199364.000000   \n",
       "mean        0.000596       0.000806      -0.000127       0.001900   \n",
       "std         1.362707       1.322962       1.216585       1.191216   \n",
       "min       -35.182120     -26.160506     -43.557242     -73.216718   \n",
       "25%        -0.690631      -0.767513      -0.556268      -0.207917   \n",
       "50%        -0.054758      -0.273142       0.040109       0.023008   \n",
       "75%         0.609794       0.400874       0.570132       0.327720   \n",
       "max        34.801666      21.550496      36.877368      20.007208   \n",
       "\n",
       "                  V9            V10  ...            V20            V21  \\\n",
       "count  199364.000000  199364.000000  ...  199364.000000  199364.000000   \n",
       "mean        0.000387      -0.000203  ...       0.000546       0.001181   \n",
       "std         1.098032       1.086637  ...       0.774205       0.736703   \n",
       "min       -13.434066     -24.588262  ...     -28.009635     -34.830382   \n",
       "25%        -0.642713      -0.535148  ...      -0.211459      -0.227817   \n",
       "50%        -0.050546      -0.091521  ...      -0.062514      -0.028990   \n",
       "75%         0.597585       0.456096  ...       0.133886       0.186863   \n",
       "max        15.594995      23.745136  ...      39.420904      27.202839   \n",
       "\n",
       "                 V22            V23            V24            V25  \\\n",
       "count  199364.000000  199364.000000  199364.000000  199364.000000   \n",
       "mean        0.000770      -0.000907       0.000708       0.000160   \n",
       "std         0.724805       0.630090       0.605543       0.520830   \n",
       "min       -10.933144     -44.807735      -2.836627     -10.295397   \n",
       "25%        -0.540206      -0.162056      -0.353481      -0.317180   \n",
       "50%         0.007585      -0.011301       0.041293       0.016244   \n",
       "75%         0.529286       0.147035       0.440205       0.351141   \n",
       "max        10.503090      22.528412       4.022866       6.070850   \n",
       "\n",
       "                 V26            V27            V28         Amount  \n",
       "count  199364.000000  199364.000000  199364.000000  199364.000000  \n",
       "mean       -0.001173      -0.000476       0.000252      88.286313  \n",
       "std         0.482453       0.401370       0.330830     248.033917  \n",
       "min        -2.604551     -22.565679     -11.710896       0.000000  \n",
       "25%        -0.328089      -0.070961      -0.053200       5.640000  \n",
       "50%        -0.053516       0.001207       0.011043      22.000000  \n",
       "75%         0.240123       0.090888       0.078216      77.000000  \n",
       "max         3.463246      12.152401      33.847808   19656.530000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터에 대한 이상치를 제거하는 작업이 필요하다.\n",
    "# 표준화를 하는 작업도 필요하다. \n",
    "# 모델을 좀더 다듬기 위해서는 위의 두 절차가 필요하다. \n",
    "# 이상치를 제거하기 위해서는 모든 열에 이상치가 있는지 찾아봐야 한다. \n",
    "X_train.describe()\n",
    "# 평균이 0인 상태이다. 표준화가 되어진 상태로 보인다. \n",
    "# 중위수가 0.015이다. 이 뜻은 평균과 어느정도 유사하다는 의미이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3353b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da6b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "04c9bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이상치 제거\n",
    "q25=np.percentile(X_train['V1'].values, 25)\n",
    "q75=np.percentile(X_train['V1'].values, 75)\n",
    "iqr=q75-q25\n",
    "iqr15=iqr*1.5\n",
    "#표준화\n",
    "# 이상치를 제거하는 것에 넘파이의 퍼센타일 함수를 쓸 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3c965897",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_val=q25-iqr15 #하한 바운더리\n",
    "highest_val=q75+iqr15#상한 바운더리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "09af9931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211605    -8.367621\n",
       "151631    -7.824182\n",
       "76190     -6.078681\n",
       "207772    -7.794335\n",
       "220170    -5.121007\n",
       "            ...    \n",
       "125442    -8.836906\n",
       "264145    -4.692089\n",
       "216442   -16.536406\n",
       "20260    -10.648382\n",
       "19760    -14.191832\n",
       "Name: V1, Length: 4928, dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['V1'][(X_train['V1']<lowest_val) | (X_train['V1']>highest_val)]\n",
    "# 하한 바운더리와 상한 바운더리의 4000개를 전부 제거한다는 것이다. \n",
    "# 무조건 제거가 능사는 아니다. 이러한 데이터들은 아웃라이어로 간주해서 제거할 수도 있지만 사용할 수 있게 바꾸는 것도 필요하다.\n",
    "# 4천개는 너무 많다. 그리고 이것들 중 정답이 없으리라는 보장도 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc49d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나중에 연습삼아서 타이타닉에도 연습을 해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "261fd5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Collecting imbalanced-learn\n",
      "  Obtaining dependency information for imbalanced-learn from https://files.pythonhosted.org/packages/a3/9e/fbe60a768502af54563dcb59ca7856f5a8833b3ad5ada658922e1ab09b7f/imbalanced_learn-0.11.0-py3-none-any.whl.metadata\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "   ---------------------------------------- 0.0/235.6 kB ? eta -:--:--\n",
      "   --------------------------------------  235.5/235.6 kB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 235.6/235.6 kB 4.8 MB/s eta 0:00:00\n",
      "Installing collected packages: imbalanced-learn\n",
      "  Attempting uninstall: imbalanced-learn\n",
      "    Found existing installation: imbalanced-learn 0.10.1\n",
      "    Uninstalling imbalanced-learn-0.10.1:\n",
      "      Successfully uninstalled imbalanced-learn-0.10.1\n",
      "Successfully installed imbalanced-learn-0.11.0\n"
     ]
    }
   ],
   "source": [
    "# smote 오버샘플링\n",
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6255ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버샘플링은 적은 데이터에 대한 과적합 문제가 발생할 수 있다. 그래서 smoth 오버샘플링을 쓴다. \n",
    "# 예를 들면 데이터가 2차원 평면상에 있을 경우라고 보자. 0 이라는 데이터가 많고 1이라는 데이터가 적다고 보자\n",
    "# 랜덤하게 1의 값을 뽑아낸다. 그 값을 중심으로 본다. 그리고 가장 가까운 1을 k개를 추출한다.\n",
    "# 그렇게 중심과 K개의 이웃과의 중간지점에 1의 값을 생성한다. 총 K개의 값이 생길것이다. 이걸 계속 반복해나간다. \n",
    "# 작업은 0과 1의 갯수가 비슷해질때까지 진행한다. \n",
    "# 이 작업이 없이 불균형적인 데이터를 사용한다면 무조건 0으로만 출력하고 정확도 99.9%를 찍게 될 것이다. 물론 0.1%는 못걸러서 쓸모없다.\n",
    "# 문제는 불균형적인 데이터를 사용하는 것은 과적합으로 이어진다.\n",
    "# 예를 들면 스팸메일에서 바카라, 바둑이, 안전한 노*리*터  같은 문자가 온다고 하자.\n",
    "# 여기서 키워드를 뽑는 것이다. 바카라.와 연관성이 높은 단어 , (홀덤, 포커)등도 찾아서 키워드화 시키는 것이다. \n",
    "# 어순을 바꾸는 것도 방법이다. 문제는 LSTM기반에서는 어순이 중요해서 어순을 바꿔서도 안된다. 가장 쓸만한 방법은 키워드 추철하는 방법이다. \n",
    "# 자연어 처리중에서는 임베딩이 존재한다. 단어 주변에 관련 단어들이 모인다. 주변의 단어들 중에서 동의어를 찾거나 유의어를 찾는 것이다. \n",
    "# 이미지 데이터도 부족하면 증식을 하게 된다. 단어가 부족하면 단어를 증식시킬 수도 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f1a07a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE # 오버샘플링에도 종류가 상당히 많다. \n",
    "# 그 중 smote를 쓰는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "242ad90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f858845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over,y_train_over = smote.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eae08803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199364, 29)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1f8b5b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398040, 29)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_over.shape\n",
    "# 자료가 두배 가까이 늘어난 것을 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "389908b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199020\n",
       "1    199020\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train_over).value_counts()\n",
    "# 갯수가 동일하게 되었다. \n",
    "# 어찌되었든 좋은 방법이라고 말하기는 어렵다. 하지만 없으면 데이터증식이라도 해야한다. \n",
    "# 인공지능 전공자도 어학계열을 전공한 사람이 유리한 이유기도 하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d91353c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버샘플링이 된 자료들을 가지고 작업을 해보자. 로지스틱 회귀를 이용해보자. \n",
    "lr_clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2921befe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(X_train_over,y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c1dd44a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = lr_clf.predict(X_test)\n",
    "ans\n",
    "# 이런 식으로 결과를 출력하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "55c84432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    84056\n",
       "1     1387\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ans).value_counts() # 쉽지 않은 것을 볼 수 있다. 너무 많이 출력이 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "196f5326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4a85b40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'breast_cancer.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스태킹(stacking)\n",
    "# 스태킹은 기본모델들이 있어야 한다.\n",
    "# 여기서는 knn,rf,dt,adaboost를 기본 모델로 설정해본다. \n",
    "cancer_data = load_breast_cancer()\n",
    "cancer_data\n",
    "# data를 보면 표준화가 되어져 있는 것으로 보인다. \n",
    "# 암세포의 모양이나 길이 등 정보들이 들어있다. \n",
    "# 타깃에는 악성인지 양성인지 나타내는 수치값이 들어있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "53b6ed71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data.data # 여기서 데이터만 써보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "edd450b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = cancer_data.data #일단 저장만 해보자. \n",
    "y_label = cancer_data.target# 정답은 레이블에 담아보자.\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9140dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_label, test_size = 0.2,random_state=20231024)\n",
    "# 테스트셋을 나눴다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7198f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스태킹은 쌓는다는 의미이다. 4개의 모델을 써보기로 했다.\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "ada_clf = AdaBoostClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "741049c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(n_estimators=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(n_estimators=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(n_estimators=100)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.fit(X_train,y_train)\n",
    "rf_clf.fit(X_train,y_train)\n",
    "dt_clf.fit(X_train,y_train)\n",
    "ada_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c22f20be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일단 궁금하긴 하다. 얘들 얼마나 잘 할지\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "ada_pred = ada_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2bd926c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298245614035088\n",
      "0.9473684210526315\n",
      "0.956140350877193\n",
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test , knn_pred))\n",
    "print(accuracy_score(y_test , rf_pred))\n",
    "print(accuracy_score(y_test , dt_pred))\n",
    "print(accuracy_score(y_test , ada_pred))\n",
    "# ada가 확실히 강력하긴 하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3cbbc2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "        0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "        0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "        1, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "        0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array([knn_pred,rf_pred, dt_pred,ada_pred])\n",
    "pred\n",
    "# 4개의 답지를 묶어보자. 4,114의 답안지가 나올 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e9afee7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 1, 1]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.transpose(pred)\n",
    "pred\n",
    "# 이거 예전에 T함수가 생각난다. \n",
    "# 이제 최종모델가지고 트레이닝을 해보면 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "535a6444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종스태킹 모델을 로지스틱회귀로 한다고 해보자.\n",
    "lr_final=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6a8336c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_final.fit(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4f1baf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = lr_final.predict(pred)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f56d94cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(final,y_test)\n",
    "# 사실상 ada boost랑 동일하다. \n",
    "# 물론 다양한 상황을 고려해야하는 시기에 이러한 방법도 있다고 알고있으면 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d84255d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추천시스템을 해보도록 하자. \n",
    "# 고객에게 가장 알맞을 만한 것을 추천하는 시스템이다. \n",
    "# 인공지능 대학원에서 석사/박사과정에 추천시스템이라는 강좌가 아예 존재한다. \n",
    "# 예를 들어  특정 물건이 구매가 이루어졌다면 함께 구매가 이루어지는 품목에 대해서 예측하는 것이다.'\n",
    "# 연관규칙은 경영학에서 많이 사용된다. 학부에서도 많이 다루기도 한다. \n",
    "# 연관분석, 일명 장바구니분석이라고 한다. \n",
    "# 우리는 장바구니 데이터를 주었을 때 이 데이터에서 규칙을 찾아내서 발견을 하는 것을 원하는 것이다. \n",
    "# 그러면 전체 거래가 있었던 목록 중 연관이 있는 것을 찾는 것이다. \n",
    "# 기저귀를 구매한 사람이 맥주를 구매하고, 빵과 우유를 구매한 사람이 달걀과 콜라를 구매했다.\n",
    "# 이러한 규칙들 중 누구나 다 아는 규칙이 있을 것이다. 빵을 사는 사람이 우유를 사는 것은 예측이 가능하다.\n",
    "# 매장의 진열대는 연관분석을 한 결과물이다. 이동경로상에 내가 찾고자 하는 물건이 있는 경우가 많이 있다. \n",
    "# 진열하는 곳 주변의 선택식품들은 관계가 있기 때문에 진열한다. \n",
    "# 술 주변에 안주거리가 있고 건조식품이 있다. \n",
    "# 서로 관련이 있는 아이템들의 규칙이라 연관규칙이라고 부른다. 이러한 연관규칙을 전체상품을 기준으로 찾고자 한다.\n",
    "# 다만 대체제, 보완재가 아닌데도 같이 구매하는 경우가 많은 경우가 있다. 기저귀와 맥주는 대체재도 아니고 보완재도 아니다. \n",
    "# 잠재 의식속의 구매패턴을 찾고자 하는 것이 연관분석을 하는 이유이다.\n",
    "# 결론적으로 고객들의 패턴을 찾기 위함이다. 의미있는 규칙이 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "13884771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제는 지역적, 환경적, 문화적으로 전부 다르다는 특징이 존재한다. 연령대에 대해서도 다르며 상업구역, 주거구역이냐에 따라서도 다르다.\n",
    "# 지역에는 관광 관련 상품을 배치하고 있다. 이런거랑 관계 있을 것이다.\n",
    "# 사업을 하는 사람에게는 연관규칙 분석이 필요하다. 서비스업과 관련되면 필수이다. \n",
    "# 개인개인에게 어떤 상품을 추천해줄 것인지에 대한 알고리즘이 있다. collaborative filtering이다. Association Rule Mining을 이번시간에 배운다.\n",
    "# 항목집합(itemset)이라는 말이 존재한다. 하나 이상의 항목의 집합을 말한다. \n",
    "# 항목집합에 항목이 몇 개가 존재하는지 확인하자. \n",
    "# 발생건수(support count)는 그 항목집합에 대한 빈도수를 조사한 것이다. \n",
    "# 서포트(support)는 전체에서 항목집합이 나온 확률이다. 즉 항목집합이 5개고 발생건수가 2개면 2/5이다. \n",
    "# 사실 집합이 있으면 중복되는 집합을 빼고 처리하는 경우가 많다. 우유가 여러개 있으면 결국 1건의 구매와 동일하게 취급하는 것이다.\n",
    "# 빈발항목집합(frequent itemset)은 최소지지인계값(mininum support threshold)이상에 해당하는 집합을 말한다. \n",
    "# 최소지지인계값은 의미를 부여할 최소값이다. 우유 구매가 3건이 초과되어야 한다고 정의할 때 3이 최소지지인계값이다. \n",
    "# 즉 빈발항목집합은 최소건수를 초과한 거래량이 나온 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fd5cd111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Association Rule Mining의 정의.\n",
    "# X라는 항목집합이 존재한다. X가 구매할 경우에 Y가 같이 구매되는 경우가 존재한다. \n",
    "# {milk,diaper}->{bread} 는 우유와 기저귀를 사는 경우 빵을 사는 것과 연결된다는 수식이다.\n",
    "# 이 규칙을 표현할 때 여러 척도가 존재한다. 지지도(Support)와 신뢰도(Confidence)가 있다.\n",
    "# 아까를 에로 들면 지지도는 2/5이며 신뢰도는 2/3이다.우유, 기저귀, 빵 3개를 다 산 경우는 2건이고 우유와 기저귀를 산 경우는 3건이다.\n",
    "# 지지도에서는 분모가 전체였지만 신뢰도에서는 수식의 시작점이 분모가 되었다. \n",
    "# 궁극적으로 두 개를 사용하는 이유는 lift를 구하기 위함이다. \n",
    "# 연관분석은 대용량 데이터베이스에서 이전에는 찾을 수 없던 아이템의 연관성을 찾을 수 있다는 것이 장점이다.\n",
    "# 마케팅 전략을 세울 경우에 필요한 기술이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "058290ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 삼겹살과 소주, 삼겹살과 쌈장을 가까히 배치하면 매출에 도움이 될 것이다. \n",
    "# 이 상황에 어떤 웹페이지를 추천할 것인지도 연관분석으로 확인 가능하다.\n",
    "# 이러한 여러가지 응용분야들이 있을 수 있다. 광고메세지를 보내더라도 광고를 읽을만한 보내는 것이 맞다. \n",
    "# 예전에는 많이 보내는 것이 좋았지만 지금은 신고당하는 것은 둘째치고 돈이 너무 많이 들어간다. \n",
    "# 구매의사가 있을 가능성이 높은 사람에 대해 광고를 하는 것이 더 효과가 좋을것이다.\n",
    "# minsup을 설정을 정확하게 해야한다. MAR의 가장 중요한 특징이다.  \n",
    "# 연관규칙을 찾고자 할 때 가장 먼저 설정하는 함수이다. 조건을 만족하는 내에서 연관규칙을 찾아내는 것이다. \n",
    "# 문제는 연관규칙이 높게 나온다고 해도 물, 라면, 우유같이 연관규칙 찾아봐야 의미없는 케으스도 많이 나온다. \n",
    "# 상품들은 지지도가 0.00001같은 것들도 많다. 연관규칙 찾는 것이 의미없다. \n",
    "# 서로 대체제와 보완재마련 연관규칙을 찾기는 매우 힘들다.\n",
    "# 정리가 잘 해야된다. 데이터의 특성에 맞게 설정을 잘 해줘야\\ 한다. \n",
    "# 룰은 높은 커니던스(신뢰도)를 가지도록 과학측에서 자주 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "13145de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈발항목 생성과정\n",
    "# 빈발항목 아이템셋을 생성할 것이다. 계산 관점에서 보면 비용이 굉장히 비쌀것이다. \n",
    "# 아아템은 2의 d승의 개념이 있을 것이다. \n",
    "# 숫자가 작으면 문제가 안된다. 2의 5승은 32이다. \n",
    "# 문제는 2의 1000승을 말하면 이건 천문학적이다. 아이템셋이 너무 많아졌다. \n",
    "# 계산상의 복잡드를 계산하면 상당할 것이다.\n",
    "# 각각의 아이템스에 대해서 만들어지는 규칙은 여러 가지일 것이다. \n",
    "# computational complexxity항목에서 나와있다. 아무리 컴퓨터가 좋아진다고 해도 몇경, 몇해의 연산량은 장난이 아니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fbd4d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아프리오리 알고리즘(illustrating Apriori Principle)\n",
    "# 최소 지지도와 신뢰도를 사전에 정하고 만족하지 않으면 그냥 버리는 것이다. 즉 조건에 만족하지 않으면 얄짤없이 버리는 것이다. \n",
    "# 반드시 사용해야한다. 아니면 2의 1000승이라는 무시무시한 계산을 인생 끝날때까지 해야한다. \n",
    "# 지지도를 만족하면 빈발항목집합이라고한다., 반대로는 비빈발항목집합(infrequent)이라고 한다. # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "84bdd581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하다보면 늘긴 한다. 계속하면 실력이 증가할 것이다. \n",
    "# 삼겹살 ->상추가 많이 있는 것을 볼 수 있다.\n",
    "# 이것이 지지도이다. 규칙에 대한 지지도이다.\n",
    "# 주의점은 시간ㅇ순서를 고려하지 않는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d5657d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신뢰도\n",
    "# 삼겹살을 사는 사람은 상추도 구매한다. 이 규칙에 대한 신뢰도를 어떻게 구할 것인가!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "979fa38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리프트분석 : 향상도를 중시한다.  L값을 조절해서 향상도를 키워보자. \n",
    "# 향상도가 무엇인지 곰곰히 생각해야 한다.\n",
    "# 기준은 1이다. 0과 1사이에서 움직인다. \n",
    "# 향상도가 1에 가까우면 거의 관계가 없다고 보면 된다.\n",
    "# 일반적으로 1보다 큰 애들에 대해 관심을 가지게 된다. \n",
    "# 1보다 작은 경우는 음의 상관관계에 해당한다. \n",
    "# 리프트가 낮은 종목을 추천하여 헷징을 하는 것도 가능하다. \n",
    "# 종목 하나에 대한것만 살 수 있겠지만 여러 가지를 사는 사람이 많다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6b7fad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레버리지: 컨피던스가 조건부 확률이다. \n",
    "# 향상도에서 비율을 이용해서 규칙에 대한 강력한 정도를 찾아낼 수 있었다면.\n",
    "# 레버리지는 차이를 찾아낸 구조였다.\n",
    "# 동시에 일어날 확률을 각각의 거래가 일어날 확률을 곱해서 뺀 것이다. \n",
    "# 이게 0에 가까울수록 이 상품은 독립이다. 연관이 없는 것이다. \n",
    "# 0보다 크다면 향상도가 1보다 큰 경우이다. 두 아이템이 관련이 있다고 본다. \n",
    "# 0보다 크거나 1보다 큰경우 두 상품은 연관성이 높다고 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "528d2211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컨빅션이라는 것이 존재한다. \n",
    "# 실제 구현하면 여러 척도들이 나오는데 특히 리프트 위주로 봐야한다. 그 규칙의 강력함을 봐야한다.\n",
    "# 규칙을 해석할때 역으로 해석하는 것이 의미가 있을 수 있다. \n",
    "# 컨빅션은 반대다. 개념적으로 잘 안쓴다.\n",
    "# 삼겹살을 구매하는데 상추를 구매하지 않을 확률이다. \n",
    "# 이것이 1일 경우 서로 관련이 없다. \n",
    "# 1보다 크다면 삼겹살에 대한 구매했을 때 상추를 구매하지 않는 경우가 줄어든다는 뜻이다. (데체 무슨말이지?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "91bd6e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분석을 할 경우 연관분석을 하는 경우는 동시에 발생한 사건을 대상으로 연관분석을 한다.\n",
    "# 그러나 순차분석이라는 것도 존재한다. 어떤걸 사고 어느 것을 나중에 샀는가? 를 연구하는 것도 존재한다. 시간도 고려하는 것이다.\n",
    "# 이런 것은 순차분석이다. 동시에 진행하는 것은 연관분석, 시간차가 존재하는 것은 순차분석이다. \n",
    "# 시간에 대한 정보에 빈발항목을 뽑아내고 거래시간을 시퀀스로 도출해낸다. \n",
    "# 옥션등에서 많이 사용하는 기술이다. 단순하게 if문이나 for문으로 끝낼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7085fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리는 쓸데없이 이런거 쓰지 않는다. 그냥 RNN(LSTM) 돌리자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b333cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[['사과','치즈','생수'],\n",
    "['생수','호두','치즈','고등어'],\n",
    "['수박','사과','생수'],\n",
    "['생수','호두','치즈','옥수수']]\n",
    "# 먼저 데이터 크기가 일정하지 않다. 3,4,3,4순이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3489031c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Obtaining dependency information for mlxtend from https://files.pythonhosted.org/packages/73/da/d5d77a9a7a135c948dbf8d3b873655b105a152d69e590150c83d23c3d070/mlxtend-0.23.0-py3-none-any.whl.metadata\n",
      "  Downloading mlxtend-0.23.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlxtend) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlxtend) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlxtend) (1.5.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlxtend) (1.3.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlxtend) (3.7.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.4 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.4 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 15.3 MB/s eta 0:00:00\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend\n",
    "# 이거 먼저 설치해보자. 아페리오리를 쓰려면 이걸 써야한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c1bdf5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2b8101b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b9ef694d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True,  True, False, False,  True, False],\n",
       "       [ True, False,  True, False, False,  True,  True],\n",
       "       [False,  True,  True,  True, False, False, False],\n",
       "       [False, False,  True, False,  True,  True,  True]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "te_ary\n",
    "# 왜이리 많을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c38d8848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['고등어', '사과', '생수', '수박', '옥수수', '치즈', '호두']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te.columns_ # 이게 순서인 것이다. \n",
    "# 솔직히 불편하다. 왜 어레이를 쓰는가? 데이터프레임으로 쉽게쉽게 살자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "12576fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>고등어</th>\n",
       "      <th>사과</th>\n",
       "      <th>생수</th>\n",
       "      <th>수박</th>\n",
       "      <th>옥수수</th>\n",
       "      <th>치즈</th>\n",
       "      <th>호두</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     고등어     사과    생수     수박    옥수수     치즈     호두\n",
       "0  False   True  True  False  False   True  False\n",
       "1   True  False  True  False  False   True   True\n",
       "2  False   True  True   True  False  False  False\n",
       "3  False  False  True  False   True   True   True"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(te_ary, columns=te.columns_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3700b59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(2, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(2, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(5, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(2, 5, 6)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support   itemsets\n",
       "0     0.50        (1)\n",
       "1     1.00        (2)\n",
       "2     0.75        (5)\n",
       "3     0.50        (6)\n",
       "4     0.50     (1, 2)\n",
       "5     0.75     (2, 5)\n",
       "6     0.50     (2, 6)\n",
       "7     0.50     (5, 6)\n",
       "8     0.50  (2, 5, 6)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아까 아페리오리를 불러왔다. \n",
    "apriori(df)\n",
    "# 규칙이 있을 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bd10aafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(사과)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>(생수)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(치즈)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(호두)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(사과, 생수)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(치즈, 생수)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(호두, 생수)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(호두, 치즈)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(호두, 치즈, 생수)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support      itemsets\n",
       "0     0.50          (사과)\n",
       "1     1.00          (생수)\n",
       "2     0.75          (치즈)\n",
       "3     0.50          (호두)\n",
       "4     0.50      (사과, 생수)\n",
       "5     0.75      (치즈, 생수)\n",
       "6     0.50      (호두, 생수)\n",
       "7     0.50      (호두, 치즈)\n",
       "8     0.50  (호두, 치즈, 생수)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori(df,min_support=0.5,use_colnames=True)# 최소지지도를 추가하였다. 그리고 열 이름도 추가했다.\n",
    "# 이걸 우리는 빈발항목집합이라고 한다. 비빈발에는 관심이 없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "16f6ec02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>(생수)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(치즈)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(치즈, 생수)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support  itemsets\n",
       "0     1.00      (생수)\n",
       "1     0.75      (치즈)\n",
       "2     0.75  (치즈, 생수)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori(df,min_support=0.75,use_colnames=True)\n",
    "# 물론 서포트는 너무 커서도, 너무 작아서도 안된다. \n",
    "# 아페리오리 사이트는 https://rasbt.github.io/mlxtend/api_subpackages/mlxtend.frequent_patterns/이다.\n",
    "# 즉 여기서 찾아보는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "880aeca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(apriori(df,min_support=0.5,use_colnames=True))\n",
    "# 판다스의 데이터프레임이라서 사용하는것은 지장없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "74aaec52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(사과)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>(생수)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(치즈)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(호두)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(사과, 생수)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.75</td>\n",
       "      <td>(치즈, 생수)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(호두, 생수)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(호두, 치즈)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.50</td>\n",
       "      <td>(호두, 치즈, 생수)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   support      itemsets\n",
       "0     0.50          (사과)\n",
       "1     1.00          (생수)\n",
       "2     0.75          (치즈)\n",
       "3     0.50          (호두)\n",
       "4     0.50      (사과, 생수)\n",
       "5     0.75      (치즈, 생수)\n",
       "6     0.50      (호두, 생수)\n",
       "7     0.50      (호두, 치즈)\n",
       "8     0.50  (호두, 치즈, 생수)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_itemsets = apriori(df,min_support=0.5,use_colnames=True)\n",
    "freq_itemsets\n",
    "# 아페리오리는 일종의 가지치기 작업이다. 서포트값을 기준으로 나오는 값을 조절한다. \n",
    "# 이제 연관규칙을 생성해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f311d755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(사과)</td>\n",
       "      <td>(생수)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(치즈)</td>\n",
       "      <td>(생수)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(호두)</td>\n",
       "      <td>(생수)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(호두)</td>\n",
       "      <td>(치즈)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(호두, 치즈)</td>\n",
       "      <td>(생수)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(호두, 생수)</td>\n",
       "      <td>(치즈)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(호두)</td>\n",
       "      <td>(치즈, 생수)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  antecedents consequents  antecedent support  consequent support  support  \\\n",
       "0        (사과)        (생수)                0.50                1.00     0.50   \n",
       "1        (치즈)        (생수)                0.75                1.00     0.75   \n",
       "2        (호두)        (생수)                0.50                1.00     0.50   \n",
       "3        (호두)        (치즈)                0.50                0.75     0.50   \n",
       "4    (호두, 치즈)        (생수)                0.50                1.00     0.50   \n",
       "5    (호두, 생수)        (치즈)                0.50                0.75     0.50   \n",
       "6        (호두)    (치즈, 생수)                0.50                0.75     0.50   \n",
       "\n",
       "   confidence      lift  leverage  conviction  zhangs_metric  \n",
       "0         1.0  1.000000     0.000         inf            0.0  \n",
       "1         1.0  1.000000     0.000         inf            0.0  \n",
       "2         1.0  1.000000     0.000         inf            0.0  \n",
       "3         1.0  1.333333     0.125         inf            0.5  \n",
       "4         1.0  1.000000     0.000         inf            0.0  \n",
       "5         1.0  1.333333     0.125         inf            0.5  \n",
       "6         1.0  1.333333     0.125         inf            0.5  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "association_rules(freq_itemsets) #연관규칙을 알기 위해서는 이걸 사용해보자.\n",
    "#lift가 높은 것을 선택하는 것이 좋다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9903b6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(호두)</td>\n",
       "      <td>(치즈)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(치즈)</td>\n",
       "      <td>(호두)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(호두, 생수)</td>\n",
       "      <td>(치즈)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(치즈, 생수)</td>\n",
       "      <td>(호두)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(호두)</td>\n",
       "      <td>(치즈, 생수)</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(치즈)</td>\n",
       "      <td>(호두, 생수)</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents  antecedent support  consequent support  support  \\\n",
       "6         (호두)        (치즈)                0.50                0.75      0.5   \n",
       "7         (치즈)        (호두)                0.75                0.50      0.5   \n",
       "9     (호두, 생수)        (치즈)                0.50                0.75      0.5   \n",
       "10    (치즈, 생수)        (호두)                0.75                0.50      0.5   \n",
       "11        (호두)    (치즈, 생수)                0.50                0.75      0.5   \n",
       "12        (치즈)    (호두, 생수)                0.75                0.50      0.5   \n",
       "\n",
       "    confidence      lift  leverage  conviction  zhangs_metric  \n",
       "6     1.000000  1.333333     0.125         inf            0.5  \n",
       "7     0.666667  1.333333     0.125         1.5            1.0  \n",
       "9     1.000000  1.333333     0.125         inf            0.5  \n",
       "10    0.666667  1.333333     0.125         1.5            1.0  \n",
       "11    1.000000  1.333333     0.125         inf            0.5  \n",
       "12    0.666667  1.333333     0.125         1.5            1.0  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = association_rules(freq_itemsets,metric='lift')\n",
    "res[res['lift']>1]\n",
    "# 향상도가 1보다 큰 결과만 뽑아낸 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c718cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리가 관심있는 분야는 antecedents와 consequents이다.\n",
    "# 즉 호두를 사면 치즈를 사는 경우가 많았다는 것이고 치즈를 사면 호두를 사는 비중이 높았다는 뜻이다. \n",
    "# 이것은 나아가면 호두 가격이 많이 오르면 치즈도 구매량이 떨어진다는 것을 예측할 수 있다. \n",
    "# 만약 맥주를 구매한 사람이 안주를 구매한 lift가 높다고 하자.\n",
    "# 맥주파동으로 맥주가 안팔리면 안주가 안팔릴 것이다. \n",
    "# 만약 안주의 가격이 오른다고 해도 맥주의 구매량에 영향을 주게 될 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db17544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나아기서 질병과 약의 관계, IoT기반 서비스의 인과관계 문제 등을 분석하는 용도로 사용 가능하다. \n",
    "# 오늘은 여기까지 해보도록 하자. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
